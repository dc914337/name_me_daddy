{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm.auto import tqdm, trange\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('äåöjkjh jhjk j1hkj', 'jfjh jhjk ef jhkj', 'jkjh jhjk jhkj')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unicodedata\n",
    "import regex as re\n",
    "\n",
    "def normalize_text(text):\n",
    "    clean_text=text.lower()\n",
    "    clean_text=re.sub(r\"[^a-zA-Z0-9\\säåö]\",\" \",clean_text)\n",
    "    #clean_text=re.sub(r\"[^\\S\\n]+\",\" \",clean_text)\n",
    "    clean_text=re.sub(r\"\\s+\",\" \",clean_text)\n",
    "    clean_text=re.sub(r\"^\\s\",\"\",clean_text)\n",
    "    clean_text=re.sub(r\"\\s$\",\"\",clean_text)\n",
    "    return clean_text\n",
    "\n",
    "normalize_text(\"äåöjkjh jhjk j1hkj\"),normalize_text(\"jFjh.jhjk,.,.ef jhkj \"),normalize_text(\" jkjh jhjk jhkj\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "finnish_company_names=[]\n",
    "with open('fullprhdata.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=';')\n",
    "    for row in csv_reader:\n",
    "        finnish_company_names.append(row[0])\n",
    "json.dump(finnish_company_names,open(\"finnish_registry_companies.json\",\"w+\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "provendix oy\n",
      "trakai oy\n",
      "zerochaos oy\n",
      "sanmet oy\n",
      "oy el ho ab\n",
      "\n",
      "Found names: 72385\n",
      "Characters: .E 0123456789abcdefghijklmnopqrstuvwxyzäåö\n",
      "Chars:  42\n",
      "Tx:  13\n"
     ]
    }
   ],
   "source": [
    "import json \n",
    "import random\n",
    "finnish_companies = json.load(open(\"finnish_registry_companies.json\",\"r+\"))\n",
    "\n",
    "Tx=13\n",
    "\n",
    "# finnish \n",
    "finnish_names_arr=[normalize_text(company) for company in finnish_companies if len(company)<Tx]\n",
    "random.shuffle(finnish_names_arr)\n",
    "finnish_names_text=\"\".join(finnish_names_arr)\n",
    "\n",
    "characters=sorted(list(set(finnish_names_text)))\n",
    "characters=[\".\",\"E\"]+characters # . is none, E is end of line\n",
    "char_indices = dict((c, i) for i, c in enumerate(characters))\n",
    "indices_char = dict((i, c) for i, c in enumerate(characters))\n",
    "\n",
    "print(\"\\n\".join(random.choices(finnish_names_arr,k=5)))\n",
    "print()\n",
    "print(f\"Found names:\", len(finnish_names_arr))\n",
    "print(\"Characters:\",\"\".join(characters))\n",
    "print(\"Chars: \",len(characters))\n",
    "print(\"Tx: \",Tx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".hello world\n"
     ]
    }
   ],
   "source": [
    "def str_to_vec(word, start_with_null=False):\n",
    "    \"\"\"\n",
    "    Converts word to vec\n",
    "    \n",
    "    word -- string\n",
    "    \n",
    "    returns array of shape (Tx, len(chars))\n",
    "    \"\"\"\n",
    "    if start_with_null:\n",
    "        word=\".\"+word\n",
    "    x = np.zeros((len(word), len(characters)), dtype=np.bool)\n",
    "    for t, char in enumerate(word):\n",
    "        x[t, char_indices[char]] = 1\n",
    "    return x\n",
    "    \n",
    "def vec_to_str(vec):\n",
    "    \"\"\"\n",
    "    Converts vec to word\n",
    "    \n",
    "    vec -- array of shape (Tx, len(chars))\n",
    "    \n",
    "    \"\"\"\n",
    "    word=\"\"\n",
    "    for i in range(vec.shape[0]):\n",
    "        word+=indices_char[np.argmax(vec[i])]\n",
    "    return word\n",
    "\n",
    "a=str_to_vec(\"hello world\",start_with_null=True)\n",
    "print(vec_to_str(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c6842c4532249fc95d9bb73bb19e16a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=72385.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((72385, 13, 42), (72385, 13, 42))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def vectorization(words, n_x, Tx=None):\n",
    "    \"\"\"\n",
    "    Convert X and Y (lists) into arrays to be given to a recurrent neural network.\n",
    "    \n",
    "    Arguments:\n",
    "    X -- \n",
    "    Y -- \n",
    "    Tx -- integer, sequence length\n",
    "    \n",
    "    Returns:\n",
    "    x -- array of shape (m, Tx, len(chars))\n",
    "    y -- array of shape (m, Tx, len(chars))\n",
    "    \"\"\"\n",
    "    if Tx is None:\n",
    "        Tx=len(max(words,key=len))\n",
    "        print(Tx)\n",
    "    \n",
    "    m = len(words)\n",
    "    x = np.zeros((m, Tx, n_x), dtype=np.bool)\n",
    "    y = np.zeros((m, Tx, n_x), dtype=np.bool)\n",
    "    \n",
    "    for w, word in enumerate(tqdm(words)):\n",
    "        word=word[:Tx]\n",
    "        x[w, 0:len(word)+1, :] = str_to_vec(word,start_with_null=True)\n",
    "        x[w, len(word)+1:, char_indices[\"E\"]] = 1\n",
    "        \n",
    "        y[w, 0:len(word),:] = str_to_vec(word)\n",
    "        y[w, len(word):, char_indices[\"E\"]] = 1\n",
    "        \n",
    "    return x, y \n",
    "\n",
    "X,Y=vectorization(finnish_names_arr, n_x=len(characters), Tx=Tx)\n",
    "X.shape, Y.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".minimer oyEE\n",
      "minimer oyEEE\n",
      "\n",
      ".lhmed oyEEEE\n",
      "lhmed oyEEEEE\n",
      "\n",
      ".aher oyEEEEE\n",
      "aher oyEEEEEE\n",
      "\n",
      ".destaplan oy\n",
      "destaplan oyE\n",
      "\n",
      ".b1g lahti oy\n",
      "b1g lahti oyE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "id_=3430\n",
    "for id_ in random.choices(range(X.shape[0]),k=5):\n",
    "    print(vec_to_str(X[id_]))\n",
    "    print(vec_to_str(np.array(Y[id_])))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diversity: 0.2\n",
      "ghai tEEEEEEE\n",
      "uclaeeEEEEEEE\n",
      "msjio EEEEEEE\n",
      "arlmatEEEEEEE\n",
      "mmatieEEEEEEE\n",
      "Diversity: 0.5\n",
      "eulua EEEEEEE\n",
      "wcia  EEEEEEE\n",
      "jkse aEEEEEEE\n",
      "mdt ttEEEEEEE\n",
      "nn ou EEEEEEE\n",
      "Diversity: 1.0\n",
      "cmzta EEEEEEE\n",
      "kart yEEEEEEE\n",
      "mnro  EEEEEEE\n",
      "tmie aEEEEEEE\n",
      "tjsoeaEEEEEEE\n",
      "Diversity: 1.2\n",
      "krewtuEEEEEEE\n",
      "bta a EEEEEEE\n",
      "yaroo EEEEEEE\n",
      "1eeie EEEEEEE\n",
      "it e eEEEEEEE\n"
     ]
    }
   ],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    out = np.random.choice(range(len(characters)), p = probas.ravel())\n",
    "    out=characters[out]\n",
    "    return out\n",
    "\n",
    "def generate_output(model, text_start, length=5):\n",
    "    \n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print(f\"Diversity: {diversity}\")\n",
    "        for l in range(length):\n",
    "            generated = '\\n'\n",
    "            sentence = ('{0:\\n>' + str(Tx) + '}').format(text_start).lower()\n",
    "            generated += text_start \n",
    "            gens=0\n",
    "\n",
    "            generated = \"\"\n",
    "            inp=text_start\n",
    "            sentence = inp\n",
    "\n",
    "            x_pred = np.zeros((1, Tx, len(characters)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.0\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            for pred in preds:\n",
    "                next_index = sample(pred)\n",
    "                next_char = next_index\n",
    "                sentence = sentence + next_char\n",
    "                generated += next_char\n",
    "            print(f\"{inp}{generated}\")\n",
    "        \n",
    "generate_output(model,\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "star oy\n"
     ]
    }
   ],
   "source": [
    "def make_name(model, beginning=\"\"):\n",
    "    name = beginning\n",
    "    x = np.zeros((1, Tx, len(characters)))\n",
    "    x[0,0:len(beginning),:]=str_to_vec(beginning,start_with_null=False)\n",
    "\n",
    "    for i in range(len(beginning),Tx-1):\n",
    "        prediction=model.predict(x)[0]\n",
    "        probs = list(prediction[i])\n",
    "        probs = probs / np.sum(probs)\n",
    "        #index = np.random.choice(range(len(characters)), p=probs)\n",
    "        index = np.argmax(prediction[i])\n",
    "        character = indices_char[index]\n",
    "        #print(f\"{vec_to_str(x[0])} -> {vec_to_str(prediction)} -> {character}\")\n",
    "        if character==\"E\":\n",
    "            break\n",
    "        name+=character\n",
    "        x[0, i+1, index] = 1\n",
    "\n",
    "        i += 1\n",
    "    \n",
    "    print(name)\n",
    "\n",
    "make_name(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 13, 64)            27392     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 13, 42)            2730      \n",
      "=================================================================\n",
      "Total params: 30,122\n",
      "Trainable params: 30,122\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers, models\n",
    "from keras.layers import Dense, Input, LSTM,GRU\n",
    "\n",
    "drp=0\n",
    "model=models.Sequential()\n",
    "model.add(LSTM(64, input_shape=(Tx, len(characters)), return_sequences=True))\n",
    "model.add(Dense(len(characters),activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import LambdaCallback\n",
    "\n",
    "def on_epoch_end(epoch, logs):\n",
    "    print()\n",
    "    for i in range(3):\n",
    "        make_name(model,\"\")\n",
    "        \n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1013/1018 [============================>.] - ETA: 0s - loss: 1.3871\n",
      "star oy\n",
      "star oy\n",
      "star oy\n",
      "1018/1018 [==============================] - 8s 8ms/step - loss: 1.3871 - val_loss: 1.4285\n",
      "Epoch 2/1000\n",
      "1017/1018 [============================>.] - ETA: 0s - loss: 1.3865\n",
      "star oy\n",
      "star oy\n",
      "star oy\n",
      "1018/1018 [==============================] - 7s 7ms/step - loss: 1.3865 - val_loss: 1.4277\n",
      "Epoch 3/1000\n",
      "1012/1018 [============================>.] - ETA: 0s - loss: 1.3859\n",
      "ster oy\n",
      "ster oy\n",
      "ster oy\n",
      "1018/1018 [==============================] - 7s 7ms/step - loss: 1.3861 - val_loss: 1.4262\n",
      "Epoch 4/1000\n",
      "1011/1018 [============================>.] - ETA: 0s - loss: 1.3854\n",
      "ster oy\n",
      "ster oy\n",
      "ster oy\n",
      "1018/1018 [==============================] - 8s 8ms/step - loss: 1.3855 - val_loss: 1.4273\n",
      "Epoch 5/1000\n",
      "1013/1018 [============================>.] - ETA: 0s - loss: 1.3851\n",
      "star oy\n",
      "star oy\n",
      "star oy\n",
      "1018/1018 [==============================] - 8s 8ms/step - loss: 1.3851 - val_loss: 1.4265\n",
      "Epoch 6/1000\n",
      "1015/1018 [============================>.] - ETA: 0s - loss: 1.3845\n",
      "star oy\n",
      "star oy\n",
      "star oy\n",
      "1018/1018 [==============================] - 7s 7ms/step - loss: 1.3845 - val_loss: 1.4280\n",
      "Epoch 7/1000\n",
      "1016/1018 [============================>.] - ETA: 0s - loss: 1.3842\n",
      "ster oy\n",
      "ster oy\n",
      "ster oy\n",
      "1018/1018 [==============================] - 7s 7ms/step - loss: 1.3841 - val_loss: 1.4267\n",
      "Epoch 8/1000\n",
      "1018/1018 [==============================] - ETA: 0s - loss: 1.3837\n",
      "ster oy\n",
      "ster oy\n",
      "ster oy\n",
      "1018/1018 [==============================] - 7s 7ms/step - loss: 1.3837 - val_loss: 1.4274\n",
      "Epoch 9/1000\n",
      "1017/1018 [============================>.] - ETA: 0s - loss: 1.3832\n",
      "ster oy\n",
      "ster oy\n",
      "ster oy\n",
      "1018/1018 [==============================] - 7s 7ms/step - loss: 1.3832 - val_loss: 1.4263\n",
      "Epoch 10/1000\n",
      "1012/1018 [============================>.] - ETA: 0s - loss: 1.3831\n",
      "star oy\n",
      "star oy\n",
      "star oy\n",
      "1018/1018 [==============================] - 7s 7ms/step - loss: 1.3828 - val_loss: 1.4301\n",
      "Epoch 11/1000\n",
      "1017/1018 [============================>.] - ETA: 0s - loss: 1.3824\n",
      "ster oy\n",
      "ster oy\n",
      "ster oy\n",
      "1018/1018 [==============================] - 7s 7ms/step - loss: 1.3824 - val_loss: 1.4278\n",
      "Epoch 12/1000\n",
      "1015/1018 [============================>.] - ETA: 0s - loss: 1.3822\n",
      "ster oy\n",
      "ster oy\n",
      "ster oy\n",
      "1018/1018 [==============================] - 8s 7ms/step - loss: 1.3821 - val_loss: 1.4267\n",
      "Epoch 13/1000\n",
      "1010/1018 [============================>.] - ETA: 0s - loss: 1.3815\n",
      "tori oy\n",
      "tori oy\n",
      "tori oy\n",
      "1018/1018 [==============================] - 7s 7ms/step - loss: 1.3816 - val_loss: 1.4281\n",
      "Epoch 14/1000\n",
      "1017/1018 [============================>.] - ETA: 0s - loss: 1.3812\n",
      "tori oy\n",
      "tori oy\n",
      "tori oy\n",
      "1018/1018 [==============================] - 7s 7ms/step - loss: 1.3812 - val_loss: 1.4265\n",
      "Epoch 15/1000\n",
      "1016/1018 [============================>.] - ETA: 0s - loss: 1.3809\n",
      "ster oy\n",
      "ster oy\n",
      "ster oy\n",
      "1018/1018 [==============================] - 7s 7ms/step - loss: 1.3809 - val_loss: 1.4268\n",
      "Epoch 16/1000\n",
      "1016/1018 [============================>.] - ETA: 0s - loss: 1.3805\n",
      "ster oy\n",
      "ster oy\n",
      "ster oy\n",
      "1018/1018 [==============================] - 7s 7ms/step - loss: 1.3805 - val_loss: 1.4265\n",
      "Epoch 17/1000\n",
      "1016/1018 [============================>.] - ETA: 0s - loss: 1.3800\n",
      "tori oy\n",
      "tori oy\n",
      "tori oy\n",
      "1018/1018 [==============================] - 7s 7ms/step - loss: 1.3801 - val_loss: 1.4260\n",
      "Epoch 18/1000\n",
      "1015/1018 [============================>.] - ETA: 0s - loss: 1.3798\n",
      "tori oy\n",
      "tori oy\n",
      "tori oy\n",
      "1018/1018 [==============================] - 8s 7ms/step - loss: 1.3798 - val_loss: 1.4269\n",
      "Epoch 19/1000\n",
      "1018/1018 [==============================] - ETA: 0s - loss: 1.3795\n",
      "tor oy\n",
      "tor oy\n",
      "tor oy\n",
      "1018/1018 [==============================] - 7s 7ms/step - loss: 1.3795 - val_loss: 1.4258\n",
      "Epoch 20/1000\n",
      "1013/1018 [============================>.] - ETA: 0s - loss: 1.3792\n",
      "ster oy\n",
      "ster oy\n",
      "ster oy\n",
      "1018/1018 [==============================] - 7s 7ms/step - loss: 1.3791 - val_loss: 1.4266\n",
      "Epoch 21/1000\n",
      "1011/1018 [============================>.] - ETA: 0s - loss: 1.3788\n",
      "ster oy\n",
      "ster oy\n",
      "ster oy\n",
      "1018/1018 [==============================] - 7s 7ms/step - loss: 1.3788 - val_loss: 1.4254\n",
      "Epoch 22/1000\n",
      "1016/1018 [============================>.] - ETA: 0s - loss: 1.3784\n",
      "ster oy\n",
      "ster oy\n",
      "ster oy\n",
      "1018/1018 [==============================] - 7s 7ms/step - loss: 1.3784 - val_loss: 1.4257\n",
      "Epoch 23/1000\n",
      "1017/1018 [============================>.] - ETA: 0s - loss: 1.3781\n",
      "tor oy\n",
      "tor oy\n",
      "tor oy\n",
      "1018/1018 [==============================] - 7s 7ms/step - loss: 1.3782 - val_loss: 1.4275\n",
      "Epoch 24/1000\n",
      "1014/1018 [============================>.] - ETA: 0s - loss: 1.3778\n",
      "star oy\n",
      "star oy\n",
      "star oy\n",
      "1018/1018 [==============================] - 8s 8ms/step - loss: 1.3779 - val_loss: 1.4274\n",
      "Epoch 25/1000\n",
      "1014/1018 [============================>.] - ETA: 0s - loss: 1.3777\n",
      "tor oy\n",
      "tor oy\n",
      "tor oy\n",
      "1018/1018 [==============================] - 7s 7ms/step - loss: 1.3776 - val_loss: 1.4259\n",
      "Epoch 26/1000\n",
      "1013/1018 [============================>.] - ETA: 0s - loss: 1.3772\n",
      "one oy\n",
      "one oy\n",
      "one oy\n",
      "1018/1018 [==============================] - 8s 8ms/step - loss: 1.3773 - val_loss: 1.4261\n",
      "Epoch 27/1000\n",
      "1016/1018 [============================>.] - ETA: 0s - loss: 1.3768\n",
      "tor oy\n",
      "tor oy\n",
      "tor oy\n",
      "1018/1018 [==============================] - 7s 7ms/step - loss: 1.3769 - val_loss: 1.4256\n",
      "Epoch 28/1000\n",
      "1011/1018 [============================>.] - ETA: 0s - loss: 1.3767\n",
      "ster oy\n",
      "ster oy\n",
      "ster oy\n",
      "1018/1018 [==============================] - 7s 7ms/step - loss: 1.3767 - val_loss: 1.4261\n",
      "Epoch 29/1000\n",
      "1016/1018 [============================>.] - ETA: 0s - loss: 1.3763\n",
      "tor oy\n",
      "tor oy\n",
      "tor oy\n",
      "1018/1018 [==============================] - 7s 7ms/step - loss: 1.3764 - val_loss: 1.4256\n",
      "Epoch 30/1000\n",
      " 236/1018 [=====>........................] - ETA: 5s - loss: 1.3738"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-0f50e8191c39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"adam\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mhistory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprint_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/kvognition/venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/kvognition/venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/kvognition/venv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/kvognition/venv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/kvognition/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/kvognition/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \"\"\"\n\u001b[0;32m-> 1843\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m~/kvognition/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/kvognition/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_build_call_outputs\u001b[0;34m(self, result)\u001b[0m\n\u001b[1;32m   2157\u001b[0m       \u001b[0mThe\u001b[0m \u001b[0mactual\u001b[0m \u001b[0mcall\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2158\u001b[0m     \"\"\"\n\u001b[0;32m-> 2159\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstructured_outputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2160\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "opt=keras.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"adam\")\n",
    "\n",
    "history=model.fit(Xf, Yf, batch_size=64, validation_split=0.1,  epochs=1000, shuffle=True, callbacks=[print_callback],verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "results=history\n",
    "\n",
    "plt.figure(figsize=(8, 16))\n",
    "plt.title(\"Learning curve\")\n",
    "plt.plot(results.history[\"loss\"], label=\"loss\")\n",
    "plt.plot(results.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot( np.argmin(results.history[\"val_loss\"]), np.min(results.history[\"val_loss\"]), marker=\"x\", color=\"r\", label=\"best model\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"log_loss\")\n",
    "plt.legend();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "\n",
    "empty=\".\"\n",
    "eos=\"E\"\n",
    "eos_index=char_indices[eos]\n",
    "xn=len(characters)\n",
    "\n",
    "\n",
    "def predict_tree(x, position, k):\n",
    "    pred=model.predict(x)[0][position]\n",
    "    indices = pred.argsort()[-k:]\n",
    "    results=np.zeros((0, Tx, xn))\n",
    "    for index in indices:\n",
    "        res=np.array(x, copy=True)\n",
    "        res[0,position,index]=pred[index]\n",
    "        if index==eos_index:\n",
    "            results=np.append(results,res,axis=0)\n",
    "            break\n",
    "        if position==Tx-1:\n",
    "            results=np.append(results,res,axis=0)\n",
    "            break\n",
    "        results=np.append(results,predict_tree(res,position+1,k), axis=0)\n",
    "    return results\n",
    "\n",
    "\n",
    "def beamsearch(k, cnt):\n",
    "    x = np.zeros((1, Tx, xn))\n",
    "    res=predict_tree(x, 0, k)\n",
    "    probs=np.sum(res,axis=(1,2))\n",
    "    samples=[vec_to_str(a) for a in np.take(res,np.argsort(probs),axis=0)[-k:]]\n",
    "    return list(zip(probs,samples))\n",
    "    \n",
    "    \n",
    "res=beamsearch(k=3,cnt=1000)\n",
    "for prob, sample in res:\n",
    "    print(f\"{probs:0.2f}: {sample}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# beam search\n",
    "# train language model for the beam search\n",
    "# end of line character should be zeros\n",
    "# dropout\n",
    "# try GRU\n",
    "# save best model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers, models\n",
    "from keras.layers import Dense, Input, LSTM,GRU\n",
    "\n",
    "drp=0\n",
    "model=models.Sequential()\n",
    "model.add(LSTM(64, input_shape=(Tx, len(characters)),return_sequences=True,activation=\"softmax\"))\n",
    "model.add(Dense(len(characters),activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(model.predict(Xf[2:3,:,:]), axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(Xf[:1,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kvognition",
   "language": "python",
   "name": "kvognition"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
