{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('jkjh jhjk j1hkj', 'jfjh jhjk ef jhkj', 'jkjh jhjk jhkj')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unicodedata\n",
    "import regex as re\n",
    "\n",
    "def normalize_text(text):\n",
    "    clean_text=text.lower()\n",
    "    clean_text=re.sub(r\"[^a-zA-Z0-9\\s]\",\" \",clean_text)\n",
    "    #clean_text=re.sub(r\"[^\\S\\n]+\",\" \",clean_text)\n",
    "    clean_text=re.sub(r\"\\s+\",\" \",clean_text)\n",
    "    clean_text=re.sub(r\"^\\s\",\"\",clean_text)\n",
    "    clean_text=re.sub(r\"\\s$\",\"\",clean_text)\n",
    "    return clean_text\n",
    "\n",
    "normalize_text(\"jkjh jhjk j1hkj\"),normalize_text(\"jFjh.jhjk,.,.ef jhkj \"),normalize_text(\" jkjh jhjk jhkj\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7173427/7173427 [01:25<00:00, 84151.57it/s]\n"
     ]
    }
   ],
   "source": [
    "import json \n",
    "import random\n",
    "finnish_companies = json.load(open(\"finnish_kaggle_companies.json\",\"r+\"))\n",
    "all_companies = json.load(open(\"all_kaggle_companies.json\",\"r+\"))\n",
    "\n",
    "names_arr=[normalize_text(company) for company in tqdm(all_companies)]\n",
    "random.shuffle(names_arr)\n",
    "names_text=\"\\n\".join(names_arr)\n",
    "characters=sorted(list(set(names_text)))\n",
    "\n",
    "char_indices = dict((c, i) for i, c in enumerate(characters))\n",
    "indices_char = dict((i, c) for i, c in enumerate(characters))\n",
    "\n",
    "Tx=20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters:  \n",
      " 0123456789abcdefghijklmnopqrstuvwxyz\n",
      "Chars:  38\n",
      "Tx:  20\n"
     ]
    }
   ],
   "source": [
    "print(\"Characters: \",\"\".join(characters))\n",
    "print(\"Chars: \",len(characters))\n",
    "print(\"Tx: \",Tx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "def str_to_vec(word):\n",
    "    \"\"\"\n",
    "    Converts word to vec\n",
    "    \n",
    "    word -- string\n",
    "    \n",
    "    returns array of shape (Tx, len(chars))\n",
    "    \"\"\"\n",
    "    x = np.zeros((len(word), len(characters)), dtype=np.bool)\n",
    "    for t, char in enumerate(word):\n",
    "        x[t, char_indices[char]] = 1\n",
    "    return x\n",
    "    \n",
    "def vec_to_str(vec):\n",
    "    \"\"\"\n",
    "    Converts vec to word\n",
    "    \n",
    "    vec -- array of shape (Tx, len(chars))\n",
    "    \n",
    "    \"\"\"\n",
    "    word=\"\"\n",
    "    for i in range(vec.shape[0]):\n",
    "        word+=indices_char[np.argmax(vec[i])]\n",
    "    return word\n",
    "\n",
    "a=str_to_vec(\"hello world\")\n",
    "#print(a)\n",
    "print(vec_to_str(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15347887/15347887 [01:44<00:00, 146752.55it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((15347887, 20, 38), (15347887, 38))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def vectorization(text, stride, n_x, Tx):\n",
    "    \"\"\"\n",
    "    Convert X and Y (lists) into arrays to be given to a recurrent neural network.\n",
    "    \n",
    "    Arguments:\n",
    "    X -- \n",
    "    Y -- \n",
    "    Tx -- integer, sequence length\n",
    "    \n",
    "    Returns:\n",
    "    x -- array of shape (m, Tx, len(chars))\n",
    "    y -- array of shape (m, Tx, len(chars))\n",
    "    \"\"\"\n",
    "    \n",
    "    m = int((len(text)-Tx-1)/stride)\n",
    "    x = np.zeros((m, Tx, n_x), dtype=np.bool)\n",
    "    y = np.zeros((m, n_x), dtype=np.bool)\n",
    "    \n",
    "    for t, i in enumerate(tqdm(range(0,m*stride,stride))):\n",
    "        fragment=text[i:i+Tx]\n",
    "        pred=text[i+Tx+1]\n",
    "        x[t, :, :] = str_to_vec(fragment)\n",
    "        \n",
    "        y[t, :] = str_to_vec(pred)\n",
    "    return x, y \n",
    "\n",
    "\n",
    "X,Y=vectorization(names, 10, n_x=len(characters), Tx=Tx)\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ino uav\\ndesch\\nsmall ', 'o')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_=2000000\n",
    "vec_to_str(X[id_]),vec_to_str(np.array([Y[id_]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_3 (GRU)                  (None, 20, 128)           64512     \n",
      "_________________________________________________________________\n",
      "gru_4 (GRU)                  (None, 128)               99072     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 38)                9766      \n",
      "=================================================================\n",
      "Total params: 206,374\n",
      "Trainable params: 206,374\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers, models\n",
    "from keras.layers import Dense, Input, LSTM,GRU\n",
    "\n",
    "\n",
    "drp=0\n",
    "model=models.Sequential()\n",
    "model.add(GRU(128, input_shape=(Tx, len(characters)),return_sequences=True, dropout=drp))\n",
    "#model.add(GRU(128,return_sequences=True, dropout=drp))\n",
    "model.add(GRU(128,return_sequences=False, dropout=drp))\n",
    "model.add(Dense(256,activation=\"relu\"))\n",
    "model.add(Dense(len(characters),activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import LambdaCallback\n",
    "\n",
    "def on_epoch_end(epoch, logs):\n",
    "    generate_output(model,\"acc\")\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " 16594/107915 [===>..........................] - ETA: 1:05:30 - loss: 2.2954"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=\"adam\")\n",
    "\n",
    "history=model.fit(X, Y, batch_size=128, validation_split=0.1,  epochs=20, shuffle=True, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Diversity: 0.2\n",
      "...Generating with seed: \" accen\"\n",
      " accenetrinoeeaeaeeeael i\n",
      "oeeoesa\n",
      "ae\n",
      "...Diversity: 0.5\n",
      "...Generating with seed: \" accen\"\n",
      " accenneer\n",
      "eeleear\n",
      "t eetnaclln\n",
      "lt\n",
      "ii\n",
      "...Diversity: 1.0\n",
      "...Generating with seed: \" accen\"\n",
      " accenim\n",
      "iritipswaonp\n",
      "uu sbrpbrsreco\n",
      "...Diversity: 1.2\n",
      "...Generating with seed: \" accen\"\n",
      " accenun oort \n",
      "roua\n",
      "cdsdimay\n",
      "a\n",
      "kinrn\n"
     ]
    }
   ],
   "source": [
    "tests=np.array([str_to_vec(a) for a in [\"ap\"]])\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    out = np.random.choice(range(len(characters)), p = probas.ravel())\n",
    "    out=characters[out]\n",
    "    return out\n",
    "\n",
    "\n",
    "for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "    print(\"...Diversity:\", diversity)\n",
    "\n",
    "    generated = \"\"\n",
    "    inp=\" accen\"\n",
    "    sentence = inp\n",
    "    print('...Generating with seed: \"' + sentence + '\"')\n",
    "\n",
    "    for i in range(30):\n",
    "        x_pred = np.zeros((1, Tx, len(characters)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x_pred[0, t, char_indices[char]] = 1.0\n",
    "        preds = model.predict(x_pred, verbose=0)[0]\n",
    "        next_index = sample(preds, diversity)\n",
    "        next_char = next_index\n",
    "        sentence = sentence + next_char\n",
    "        generated += next_char\n",
    "    print(inp+generated)\n",
    "\n",
    "\n",
    "#[vec_to_str(res) for res in ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accenti\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_output(model, text_start, length=30):\n",
    "    generated = '\\n'\n",
    "    sentence = ('{0:0>' + str(Tx) + '}').format(text_start).lower()\n",
    "    generated += text_start \n",
    "\n",
    "    for i in range(length):\n",
    "        x_pred = np.zeros((1, Tx, len(characters)))\n",
    "\n",
    "        for t, char in enumerate(sentence):\n",
    "            if char != '0':\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "        preds = model.predict(x_pred, verbose=0)[0]\n",
    "        next_index = sample(preds, temperature = 1.0)\n",
    "        next_char = next_index\n",
    "\n",
    "        generated += next_char\n",
    "        sentence = sentence[1:] + next_char\n",
    "\n",
    "        if next_char == '\\n':\n",
    "            print(generated)\n",
    "            return\n",
    "    print(generated)\n",
    "    \n",
    "generate_output(model,\"accent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kvognition",
   "language": "python",
   "name": "kvognition"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
