{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: | \n",
      "The environment is inconsistent, please check the package plan carefully\n",
      "The following packages are causing the inconsistency:\n",
      "\n",
      "  - defaults/linux-64::pandas==1.0.1=py36h0573a6f_0\n",
      "  - defaults/noarch::jupyterlab==1.2.6=pyhf63ae98_0\n",
      "  - defaults/linux-64::scikit-learn==0.22.1=py36hd81dba3_0\n",
      "  - defaults/linux-64::python-language-server==0.31.7=py36_0\n",
      "  - defaults/linux-64::bkcharts==0.2=py36_0\n",
      "  - defaults/linux-64::nb_conda==2.2.1=py36_0\n",
      "  - defaults/noarch::numpydoc==0.9.2=py_0\n",
      "  - defaults/linux-64::pytest-arraydiff==0.3=py36h39e3cac_0\n",
      "  - defaults/linux-64::bottleneck==1.3.2=py36heb32a55_0\n",
      "  - defaults/noarch::sphinx==2.4.0=py_0\n",
      "  - defaults/linux-64::pywavelets==1.1.1=py36h7b6447c_0\n",
      "  - defaults/noarch::pytest-astropy==0.8.0=py_0\n",
      "  - defaults/linux-64::numexpr==2.7.1=py36h423224d_0\n",
      "  - defaults/noarch::anaconda-project==0.8.4=py_0\n",
      "  - defaults/linux-64::nbconvert==5.6.1=py36_0\n",
      "  - defaults/linux-64::h5py==2.10.0=py36h7918eee_0\n",
      "  - defaults/linux-64::bokeh==1.4.0=py36_0\n",
      "  - defaults/noarch::jupyterlab_server==1.0.6=py_0\n",
      "  - defaults/linux-64::numpy-base==1.18.1=py36hde5b4d6_1\n",
      "  - defaults/linux-64::jupyter==1.0.0=py36_7\n",
      "  - defaults/linux-64::astropy==4.0=py36h7b6447c_0\n",
      "  - defaults/linux-64::patsy==0.5.1=py36_0\n",
      "  - defaults/linux-64::scikit-image==0.16.2=py36h0573a6f_0\n",
      "  - defaults/linux-64::matplotlib-base==3.1.3=py36hef1b27d_0\n",
      "  - defaults/linux-64::imageio==2.6.1=py36_0\n",
      "  - defaults/linux-64::pytables==3.6.1=py36h71ec239_0\n",
      "  - defaults/linux-64::nb_conda_kernels==2.2.4=py36_0\n",
      "  - defaults/linux-64::mkl_fft==1.0.15=py36ha843d7b_0\n",
      "  - defaults/linux-64::statsmodels==0.11.0=py36h7b6447c_0\n",
      "  - defaults/linux-64::spyder==4.0.1=py36_0\n",
      "  - defaults/noarch::seaborn==0.10.0=py_0\n",
      "  - defaults/linux-64::requests==2.22.0=py36_1\n",
      "  - defaults/linux-64::numba==0.48.0=py36h0573a6f_0\n",
      "  - defaults/linux-64::scipy==1.4.1=py36h0b6359f_0\n",
      "  - defaults/noarch::pytest-doctestplus==0.5.0=py_0\n",
      "  - defaults/linux-64::mkl_random==1.1.0=py36hd6b4f25_0\n",
      "  - defaults/noarch::dask==2.11.0=py_0\n",
      "  - defaults/noarch::ipywidgets==7.5.1=py_0\n",
      "  - defaults/linux-64::widgetsnbextension==3.5.1=py36_0\n",
      "  - defaults/noarch::s3fs==0.4.2=py_0\n",
      "  - defaults/linux-64::notebook==6.0.3=py36_0\n",
      "  - defaults/linux-64::matplotlib==3.1.3=py36_0\n",
      "  - defaults/linux-64::anaconda-client==1.7.2=py36_0\n",
      "  - defaults/linux-64::numpy==1.18.1=py36h4f9e942_0\n",
      "failed with initial frozen solve. Retrying with flexible solve.\n",
      "Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: \\ \n",
      "The environment is inconsistent, please check the package plan carefully\n",
      "The following packages are causing the inconsistency:\n",
      "\n",
      "  - defaults/noarch::jupyterlab==1.2.6=pyhf63ae98_0\n",
      "  - defaults/linux-64::python-language-server==0.31.7=py36_0\n",
      "  - defaults/linux-64::nb_conda==2.2.1=py36_0\n",
      "  - defaults/noarch::numpydoc==0.9.2=py_0\n",
      "  - defaults/noarch::sphinx==2.4.0=py_0\n",
      "  - defaults/noarch::anaconda-project==0.8.4=py_0\n",
      "  - defaults/linux-64::nbconvert==5.6.1=py36_0\n",
      "  - defaults/noarch::jupyterlab_server==1.0.6=py_0\n",
      "  - defaults/linux-64::jupyter==1.0.0=py36_7\n",
      "  - defaults/linux-64::nb_conda_kernels==2.2.4=py36_0\n",
      "  - defaults/linux-64::spyder==4.0.1=py36_0\n",
      "  - defaults/linux-64::requests==2.22.0=py36_1\n",
      "  - defaults/noarch::ipywidgets==7.5.1=py_0\n",
      "  - defaults/linux-64::widgetsnbextension==3.5.1=py36_0\n",
      "  - defaults/noarch::s3fs==0.4.2=py_0\n",
      "  - defaults/linux-64::notebook==6.0.3=py36_0\n",
      "  - defaults/linux-64::anaconda-client==1.7.2=py36_0\n",
      "done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.8.3\n",
      "  latest version: 4.9.2\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/ec2-user/anaconda3/envs/tensorflow2_p36\n",
      "\n",
      "  added / updated specs:\n",
      "    - regex\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    astroid-2.4.2              |   py36h9f0ad1d_1         297 KB  conda-forge\n",
      "    boto3-1.16.23              |     pyhd8ed1ab_0          70 KB  conda-forge\n",
      "    botocore-1.19.23           |     pyhd8ed1ab_0         4.2 MB  conda-forge\n",
      "    ca-certificates-2020.11.8  |       ha878542_0         145 KB  conda-forge\n",
      "    certifi-2020.11.8          |   py36h5fab9bb_0         150 KB  conda-forge\n",
      "    docutils-0.16              |   py36h9880bd3_2         736 KB  conda-forge\n",
      "    pylint-2.6.0               |   py36h9f0ad1d_1         446 KB  conda-forge\n",
      "    regex-2020.11.13           |   py36h1d69622_0         358 KB  conda-forge\n",
      "    toml-0.10.2                |     pyhd8ed1ab_0          18 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         6.4 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  astroid            conda-forge/linux-64::astroid-2.4.2-py36h9f0ad1d_1\n",
      "  bleach             conda-forge/noarch::bleach-3.2.1-pyh9f0ad1d_0\n",
      "  boto3              conda-forge/noarch::boto3-1.16.23-pyhd8ed1ab_0\n",
      "  botocore           conda-forge/noarch::botocore-1.19.23-pyhd8ed1ab_0\n",
      "  brotlipy           conda-forge/linux-64::brotlipy-0.7.0-py36he6145b8_1001\n",
      "  docutils           conda-forge/linux-64::docutils-0.16-py36h9880bd3_2\n",
      "  pylint             conda-forge/linux-64::pylint-2.6.0-py36h9f0ad1d_1\n",
      "  regex              conda-forge/linux-64::regex-2020.11.13-py36h1d69622_0\n",
      "  s3transfer         conda-forge/noarch::s3transfer-0.3.3-py_3\n",
      "  toml               conda-forge/noarch::toml-0.10.2-pyhd8ed1ab_0\n",
      "  urllib3            conda-forge/noarch::urllib3-1.25.11-py_0\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates                      2020.6.20-hecda079_0 --> 2020.11.8-ha878542_0\n",
      "  certifi                          2020.6.20-py36h9880bd3_2 --> 2020.11.8-py36h5fab9bb_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "pylint-2.6.0         | 446 KB    | ##################################### | 100% \n",
      "regex-2020.11.13     | 358 KB    | ##################################### | 100% \n",
      "boto3-1.16.23        | 70 KB     | ##################################### | 100% \n",
      "docutils-0.16        | 736 KB    | ##################################### | 100% \n",
      "astroid-2.4.2        | 297 KB    | ##################################### | 100% \n",
      "certifi-2020.11.8    | 150 KB    | ##################################### | 100% \n",
      "botocore-1.19.23     | 4.2 MB    | ##################################### | 100% \n",
      "toml-0.10.2          | 18 KB     | ##################################### | 100% \n",
      "ca-certificates-2020 | 145 KB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%conda install regex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('äåöjkjh jhjk j1hkj', 'jfjh jhjk ef jhkj', 'jkjh jhjk jhkj')"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unicodedata\n",
    "import regex as re\n",
    "\n",
    "def normalize_text(text):\n",
    "    clean_text=text.lower()\n",
    "    clean_text=re.sub(r\"[^a-zA-Z0-9\\säåö]\",\" \",clean_text)\n",
    "    #clean_text=re.sub(r\"[^\\S\\n]+\",\" \",clean_text)\n",
    "    clean_text=re.sub(r\"\\s+\",\" \",clean_text)\n",
    "    clean_text=re.sub(r\"^\\s\",\"\",clean_text)\n",
    "    clean_text=re.sub(r\"\\s$\",\"\",clean_text)\n",
    "    return clean_text\n",
    "\n",
    "normalize_text(\"äåöjkjh jhjk j1hkj\"),normalize_text(\"jFjh.jhjk,.,.ef jhkj \"),normalize_text(\" jkjh jhjk jhkj\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "finnish_company_names=[]\n",
    "with open('fullprhdata.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=';')\n",
    "    for row in csv_reader:\n",
    "        finnish_company_names.append(row[0])\n",
    "json.dump(finnish_company_names,open(\"finnish_registry_companies.json\",\"w+\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/7173427 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 5540/7173427 [00:00<02:09, 55391.73it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 10852/7173427 [00:00<02:10, 54688.35it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 16124/7173427 [00:00<02:12, 54080.02it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 21478/7173427 [00:00<02:12, 53915.96it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 26802/7173427 [00:00<02:13, 53708.60it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 32164/7173427 [00:00<02:13, 53681.01it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  1%|          | 37589/7173427 [00:00<02:12, 53848.97it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  1%|          | 43019/7173427 [00:00<02:12, 53980.97it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  1%|          | 48576/7173427 [00:00<02:10, 54446.28it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  1%|          | 54021/7173427 [00:01<02:10, 54445.23it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  1%|          | 59526/7173427 [00:01<02:10, 54623.30it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  1%|          | 64880/7173427 [00:01<02:10, 54289.73it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  1%|          | 70273/7173427 [00:01<02:11, 54180.55it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  1%|          | 75791/7173427 [00:01<02:10, 54475.31it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  1%|          | 81296/7173427 [00:01<02:09, 54643.83it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  1%|          | 86756/7173427 [00:01<02:09, 54629.12it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  1%|▏         | 92202/7173427 [00:01<02:10, 54246.34it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  1%|▏         | 97615/7173427 [00:01<02:10, 54033.39it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  1%|▏         | 103131/7173427 [00:01<02:10, 54366.14it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  2%|▏         | 108600/7173427 [00:02<02:09, 54460.70it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  2%|▏         | 114043/7173427 [00:02<02:10, 53891.55it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  2%|▏         | 119431/7173427 [00:02<02:12, 53042.54it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  2%|▏         | 124784/7173427 [00:02<02:12, 53186.16it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  2%|▏         | 130105/7173427 [00:02<02:12, 52971.52it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  2%|▏         | 135572/7173427 [00:02<02:11, 53467.65it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  2%|▏         | 141081/7173427 [00:02<02:10, 53941.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  2%|▏         | 146478/7173427 [00:02<02:11, 53339.01it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-347-42ce7705f60e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# companies\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mnames_arr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnormalize_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompany\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcompany\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_companies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames_arr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mnames_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames_arr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-347-42ce7705f60e>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# companies\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mnames_arr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnormalize_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompany\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcompany\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_companies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames_arr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mnames_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames_arr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-276-7670eff5ddaf>\u001b[0m in \u001b[0;36mnormalize_text\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m#clean_text=re.sub(r\"[^\\S\\n]+\",\" \",clean_text)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mclean_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"\\s+\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclean_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mclean_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"^\\s\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclean_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mclean_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"\\s$\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclean_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mclean_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/regex/regex.py\u001b[0m in \u001b[0;36msub\u001b[0;34m(pattern, repl, string, count, flags, pos, endpos, concurrent, timeout, ignore_unused, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m     object and must return a replacement string to be used.\"\"\"\n\u001b[1;32m    277\u001b[0m     \u001b[0mpat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_unused\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mpat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcurrent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m def subf(pattern, format, string, count=0, flags=0, pos=None, endpos=None,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  2%|▏         | 146478/7173427 [00:18<02:11, 53339.01it/s]\u001b[A\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "import json \n",
    "import random\n",
    "finnish_companies = json.load(open(\"finnish_registry_companies.json\",\"r+\"))\n",
    "all_companies = json.load(open(\"all_kaggle_companies.json\",\"r+\"))\n",
    "\n",
    "# companies \n",
    "names_arr=[normalize_text(company) for company in tqdm(all_companies)]\n",
    "random.shuffle(names_arr)\n",
    "names_text=\"\\n\".join(names_arr)\n",
    "\n",
    "# finnish \n",
    "finnish_names_arr=[normalize_text(company) for company in tqdm(finnish_companies)]\n",
    "random.shuffle(finnish_names_arr)\n",
    "finnish_names_text=\"\\n\".join(finnish_names_arr)\n",
    "\n",
    "\n",
    "characters=sorted(list(set(names_text+finnish_names_text)))\n",
    "characters=\".\"+characters # . is none\n",
    "char_indices = dict((c, i) for i, c in enumerate(characters))\n",
    "indices_char = dict((i, c) for i, c in enumerate(characters))\n",
    "\n",
    "Tx=25\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Characters:\",\"\".join(characters))\n",
    "print(\"Chars: \",len(characters))\n",
    "print(\"Tx: \",Tx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_to_vec(word, start_with_null=False):\n",
    "    \"\"\"\n",
    "    Converts word to vec\n",
    "    \n",
    "    word -- string\n",
    "    \n",
    "    returns array of shape (Tx, len(chars))\n",
    "    \"\"\"\n",
    "    if start_with_null:\n",
    "        word=\".\"+word\n",
    "    x = np.zeros((len(word), len(characters)), dtype=np.bool)\n",
    "    for t, char in enumerate(word):\n",
    "        x[t, char_indices[char]] = 1\n",
    "    return x\n",
    "    \n",
    "def vec_to_str(vec):\n",
    "    \"\"\"\n",
    "    Converts vec to word\n",
    "    \n",
    "    vec -- array of shape (Tx, len(chars))\n",
    "    \n",
    "    \"\"\"\n",
    "    word=\"\"\n",
    "    for i in range(vec.shape[0]):\n",
    "        word+=indices_char[np.argmax(vec[i])]\n",
    "    return word\n",
    "\n",
    "a=str_to_vec(\"hello world\",start_with_null=True)\n",
    "#print(a)\n",
    "print(vec_to_str(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorization(text, stride, n_x, Tx):\n",
    "    \"\"\"\n",
    "    Convert X and Y (lists) into arrays to be given to a recurrent neural network.\n",
    "    \n",
    "    Arguments:\n",
    "    X -- \n",
    "    Y -- \n",
    "    Tx -- integer, sequence length\n",
    "    \n",
    "    Returns:\n",
    "    x -- array of shape (m, Tx, len(chars))\n",
    "    y -- array of shape (m, Tx, len(chars))\n",
    "    \"\"\"\n",
    "    \n",
    "    m = int((len(text)-Tx-1)/stride)\n",
    "    x = np.zeros((m, Tx, n_x), dtype=np.bool)\n",
    "    y = np.zeros((m, Tx, n_x), dtype=np.bool)\n",
    "    \n",
    "    for t, i in enumerate(tqdm(range(0,m*stride,stride))):\n",
    "        fragment=text[i:i+Tx]\n",
    "        pred=text[i+1:i+Tx+1]\n",
    "        x[t, :, :] = str_to_vec(fragment)\n",
    "        y[t,:, :] = str_to_vec(pred)\n",
    "        \n",
    "    return x, y \n",
    "\n",
    "X,Y=vectorization(names_text, 10, n_x=len(characters), Tx=Tx)\n",
    "Xf,Yf=vectorization(finnish_names_text, 10, n_x=len(characters), Tx=Tx)\n",
    "X.shape, Y.shape, Xf.shape, Yf.shape, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_=3430\n",
    "vec_to_str(Xf[id_]),vec_to_str(np.array(Yf[id_]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diversity: 0.2\n",
      "accentdoenseo aeptsuieiunsalotwitnouta\n",
      "accentpkc tslss o ustrtsau itao urt  v\n",
      "accent3h stela tlyaiaautseepraa midptc\n",
      "accentblh fipoeea be1niutttsgtalolnsde\n",
      "accentlsestef sc eipeiysreysuiteo tspt\n",
      "Diversity: 0.5\n",
      "accenttlurtioldce tasiat ucoitfayaw ui\n",
      "accentpcuntrragia i rksctiaa ftaai ena\n",
      "accentcioätes g lysift toiiopiuiethtii\n",
      "accentiteltec eet  n  smmrtoonyugudtoa\n",
      "accenttaamtol  iaolel toayt esu vtitua\n",
      "Diversity: 1.0\n",
      "accentmgelliouya esyilannf oyos iyyrte\n",
      "accentq obtelsl scsyai  uwabyua oitgit\n",
      "accentroordhoviisaaptlawvusyn ctoelaao\n",
      "accentw oxteiyreioaasatpauut ecxaecf s\n",
      "accentkoorte   m sytsa soe caisay  eso\n",
      "Diversity: 1.2\n",
      "accentdrorcuy aire islcfistattouaulatt\n",
      "accentwpemteea bi iayisiesg ogttti csm\n",
      "accent1yyrt r l s tcpiifttsionaepotivt\n",
      "accentmotttea latyesossrusryacoi tirtt\n",
      "accentyooxtea sumumroilecat eetfaaumpa\n"
     ]
    }
   ],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    out = np.random.choice(range(len(characters)), p = probas.ravel())\n",
    "    out=characters[out]\n",
    "    return out\n",
    "\n",
    "def generate_output(model, text_start, length=5):\n",
    "    \n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print(f\"Diversity: {diversity}\")\n",
    "        for l in range(length):\n",
    "            generated = '\\n'\n",
    "            sentence = ('{0:\\n>' + str(Tx) + '}').format(text_start).lower()\n",
    "            generated += text_start \n",
    "            gens=0\n",
    "\n",
    "            generated = \"\"\n",
    "            inp=text_start\n",
    "            sentence = inp\n",
    "\n",
    "            x_pred = np.zeros((1, Tx, len(characters)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.0\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            for pred in preds:\n",
    "                next_index = sample(pred)\n",
    "                next_char = next_index\n",
    "                sentence = sentence + next_char\n",
    "                generated += next_char\n",
    "            print(f\"{inp}{generated}\")\n",
    "        \n",
    "generate_output(model,\"accent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 25, 128)           87040     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 25, 41)            5289      \n",
      "=================================================================\n",
      "Total params: 92,329\n",
      "Trainable params: 92,329\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers, models\n",
    "from keras.layers import Dense, Input, LSTM,GRU\n",
    "\n",
    "drp=0\n",
    "model=models.Sequential()\n",
    "model.add(LSTM(128, input_shape=(Tx, len(characters)),return_sequences=True))\n",
    "model.add(Dense(len(characters),activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import LambdaCallback\n",
    "\n",
    "def on_epoch_end(epoch, logs):\n",
    "    generate_output(model,\"acc\")\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13813600 samples, validate on 1534845 samples\n",
      "Epoch 1/100\n",
      "13813600/13813600 [==============================] - 659s 48us/step - loss: 2.0369 - val_loss: 1.8503\n",
      "===Diversity: 0.2 ===\n",
      "accthtklheti taihcgrit peelc\n",
      "===Diversity: 0.5 ===\n",
      "accncye tbirialeaierhs  utlb\n",
      "===Diversity: 1.0 ===\n",
      "acclkeutae8lvk e rigiiolvoas\n",
      "===Diversity: 1.2 ===\n",
      "accneodoiamildaa ifiuorhtic \n",
      "Epoch 2/100\n",
      "13813600/13813600 [==============================] - 655s 47us/step - loss: 1.8073 - val_loss: 1.7804\n",
      "===Diversity: 0.2 ===\n",
      "accnteumteih piho rciirisdet\n",
      "===Diversity: 0.5 ===\n",
      "acc tedacezailtotiannaryoe\n",
      "i\n",
      "===Diversity: 1.0 ===\n",
      "acc veunsiirlltm\n",
      " udctp isgv\n",
      "===Diversity: 1.2 ===\n",
      "accsoautrgbfr aroieaiegeiirj\n",
      "Epoch 3/100\n",
      "13813600/13813600 [==============================] - 657s 48us/step - loss: 1.7636 - val_loss: 1.7532\n",
      "===Diversity: 0.2 ===\n",
      "acc tluua azasiimsiaryaet\n",
      "im\n",
      "===Diversity: 0.5 ===\n",
      "accckoddo eaminilrihssteairi\n",
      "===Diversity: 1.0 ===\n",
      "acc t ssiui iazvtveamestwazs\n",
      "===Diversity: 1.2 ===\n",
      "accliosrjestdat jislirmsiiof\n",
      "Epoch 4/100\n",
      "13813600/13813600 [==============================] - 655s 47us/step - loss: 1.7433 - val_loss: 1.7380\n",
      "===Diversity: 0.2 ===\n",
      "acclkonnciryrkrcsit iuiälrft\n",
      "===Diversity: 0.5 ===\n",
      "acc iasedtgigikubkumriamslgu\n",
      "===Diversity: 1.0 ===\n",
      "accthlrnfmreeigriamrrrgitsl \n",
      "===Diversity: 1.2 ===\n",
      "accdohroryngbilsgraefkyumheh\n",
      "Epoch 5/100\n",
      "13813600/13813600 [==============================] - 653s 47us/step - loss: 1.7311 - val_loss: 1.7282\n",
      "===Diversity: 0.2 ===\n",
      "acc\n",
      "sypeikitlesafsraejysgjuu\n",
      "===Diversity: 0.5 ===\n",
      "accsqalartlsitk\n",
      "jimkuiirza\n",
      "i\n",
      "===Diversity: 1.0 ===\n",
      "accutiualgrchla seoissituz e\n",
      "===Diversity: 1.2 ===\n",
      "accmielsueyei  th eiiruijjlg\n",
      "Epoch 6/100\n",
      "13813600/13813600 [==============================] - 653s 47us/step - loss: 1.7229 - val_loss: 1.7216\n",
      "===Diversity: 0.2 ===\n",
      "accriiur  o3ttkurdtditri\n",
      "siu\n",
      "===Diversity: 0.5 ===\n",
      "acciooinssm\n",
      "fki\n",
      "dri\n",
      "ttcasere\n",
      "===Diversity: 1.0 ===\n",
      "acctcestiochlecuugaeinrkjmee\n",
      "===Diversity: 1.2 ===\n",
      "acc oeentye\n",
      "\n",
      "evhiaatdaeoualo\n",
      "Epoch 7/100\n",
      "13813600/13813600 [==============================] - 653s 47us/step - loss: 1.7170 - val_loss: 1.7165\n",
      "===Diversity: 0.2 ===\n",
      "accctilnsjeie\n",
      "naasgbkilreeei\n",
      "===Diversity: 0.5 ===\n",
      "accb ipaceirisdiarmiiijimkes\n",
      "===Diversity: 1.0 ===\n",
      "accltosrc\n",
      "igitimruurtalahsgu\n",
      "===Diversity: 1.2 ===\n",
      "accraosaai\n",
      " lmivneseedkckmek\n",
      "Epoch 8/100\n",
      "13813600/13813600 [==============================] - 654s 47us/step - loss: 1.7124 - val_loss: 1.7127\n",
      "===Diversity: 0.2 ===\n",
      "accrthinrjaaiskyusigkgugtdrv\n",
      "===Diversity: 0.5 ===\n",
      "acccoolaaiivro\n",
      "ltrkhrbrölbxu\n",
      "===Diversity: 1.0 ===\n",
      "accccodntarreiadlumiwekhgija\n",
      "===Diversity: 1.2 ===\n",
      "accgh sn lirsolhh\n",
      "cihalk5eah\n",
      "Epoch 9/100\n",
      "13813600/13813600 [==============================] - 654s 47us/step - loss: 1.7087 - val_loss: 1.7096\n",
      "===Diversity: 0.2 ===\n",
      "accitoecackssaaeg\n",
      "idnanameos\n",
      "===Diversity: 0.5 ===\n",
      "accliolnpgi\n",
      "raaikr\n",
      "odsmjajmm\n",
      "===Diversity: 1.0 ===\n",
      "acct\n",
      "elrsisslrujtr muglrisco\n",
      "===Diversity: 1.2 ===\n",
      "accriednlygrtlmsgkgrtresurko\n",
      "Epoch 10/100\n",
      "13813600/13813600 [==============================] - 655s 47us/step - loss: 1.7057 - val_loss: 1.7061\n",
      "===Diversity: 0.2 ===\n",
      "accpcfrok loehrkeauppalisaoi\n",
      "===Diversity: 0.5 ===\n",
      "accgoid tiliuefalriiiviruoak\n",
      "===Diversity: 1.0 ===\n",
      "acc iile\n",
      "hugr evcaispzikaiyr\n",
      "===Diversity: 1.2 ===\n",
      "acc iefa ltbgjrjku eaililbwk\n",
      "Epoch 11/100\n",
      "13813600/13813600 [==============================] - 654s 47us/step - loss: 1.7031 - val_loss: 1.7042\n",
      "===Diversity: 0.2 ===\n",
      "accnnaucd\n",
      "dkiteiwkpwrsemjagf\n",
      "===Diversity: 0.5 ===\n",
      "accltlorkeafeerogtrlkvhkgias\n",
      "===Diversity: 1.0 ===\n",
      "accbtonippesalt \n",
      "sukerortutv\n",
      "===Diversity: 1.2 ===\n",
      "accuaisctcjaiitlicjuga pulil\n",
      "Epoch 12/100\n",
      "13813600/13813600 [==============================] - 653s 47us/step - loss: 1.7009 - val_loss: 1.7019\n",
      "===Diversity: 0.2 ===\n",
      "accv ouls\n",
      "lesc rzzsankaagev\n",
      "\n",
      "===Diversity: 0.5 ===\n",
      "acc konr\n",
      "titeaegggmieljonryt\n",
      "===Diversity: 1.0 ===\n",
      "acc colorrasluprslvkkrakt\n",
      "ii\n",
      "===Diversity: 1.2 ===\n",
      "accnhulrurs\n",
      "usti\n",
      "eezullksdei\n",
      "Epoch 13/100\n",
      "13813600/13813600 [==============================] - 653s 47us/step - loss: 1.6991 - val_loss: 1.7004\n",
      "===Diversity: 0.2 ===\n",
      "accr\n",
      "edishio\n",
      "plurrjgadidleih\n",
      "===Diversity: 0.5 ===\n",
      "acclsilraltrjdkdiujimgkaoctu\n",
      "===Diversity: 1.0 ===\n",
      "acc ialrlhuliiaayilgjiebalga\n",
      "===Diversity: 1.2 ===\n",
      "acclthebkzigibimirribalkieku\n",
      "Epoch 14/100\n",
      "13813600/13813600 [==============================] - 653s 47us/step - loss: 1.6975 - val_loss: 1.6990\n",
      "===Diversity: 0.2 ===\n",
      "accntolcbiaharlsjdin7pisgbts\n",
      "===Diversity: 0.5 ===\n",
      "accuholrltuslriegtsisofilaba\n",
      "===Diversity: 1.0 ===\n",
      "acc helrllkjljaljaaeigpunahi\n",
      "===Diversity: 1.2 ===\n",
      "accgcolracisltuuiikidletrsel\n",
      "Epoch 15/100\n",
      "13813600/13813600 [==============================] - 653s 47us/step - loss: 1.6961 - val_loss: 1.6977\n",
      "===Diversity: 0.2 ===\n",
      "acc oodccht gcadlssaoatnguhn\n",
      "===Diversity: 0.5 ===\n",
      "acclkolrnitsju\n",
      "m\n",
      "aaagalrzeki\n",
      "===Diversity: 1.0 ===\n",
      "acclioerotagiollegmeu ghjpna\n",
      "===Diversity: 1.2 ===\n",
      "accstafcetictopta\n",
      "cglkirla l\n",
      "Epoch 16/100\n",
      "13813600/13813600 [==============================] - 660s 48us/step - loss: 1.6948 - val_loss: 1.6967\n",
      "===Diversity: 0.2 ===\n",
      "acc halrdsuvvtei gltmaikkkms\n",
      "===Diversity: 0.5 ===\n",
      "acc kisllthafsfsdk\n",
      "rjtkuotjk\n",
      "===Diversity: 1.0 ===\n",
      "accukelrctpurj iglauerrnlnio\n",
      "===Diversity: 1.2 ===\n",
      "accm osr\n",
      "ev\n",
      "iikrnbsikuwibdvu\n",
      "Epoch 17/100\n",
      "13813600/13813600 [==============================] - 655s 47us/step - loss: 1.6936 - val_loss: 1.6951\n",
      "===Diversity: 0.2 ===\n",
      "accgkoifzuukakkjhriuapaiiekf\n",
      "===Diversity: 0.5 ===\n",
      "accttelr\n",
      "riuh tg aajköaiakas\n",
      "===Diversity: 1.0 ===\n",
      "accutpurfl\n",
      "kitsldaavirilia l\n",
      "===Diversity: 1.2 ===\n",
      "accnkklriccdr agrtsrliidalks\n",
      "Epoch 18/100\n",
      "13813600/13813600 [==============================] - 660s 48us/step - loss: 1.6926 - val_loss: 1.6940\n",
      "===Diversity: 0.2 ===\n",
      "accstalztuaseahgrmkkklmzkoki\n",
      "===Diversity: 0.5 ===\n",
      "accnialwrrapsrlohjsaisrkzöir\n",
      "===Diversity: 1.0 ===\n",
      "accltelaxtuiasuspaseh\n",
      "muoki\n",
      "\n",
      "===Diversity: 1.2 ===\n",
      "acciu\n",
      "ltcaijigr ieunukahtrii\n",
      "Epoch 19/100\n",
      "13813600/13813600 [==============================] - 653s 47us/step - loss: 1.6916 - val_loss: 1.6936\n",
      "===Diversity: 0.2 ===\n",
      "acclkesitgiirjlgkkk ltg\n",
      "\n",
      "lku\n",
      "===Diversity: 0.5 ===\n",
      "accnskdrl\n",
      "arjipkbelfzualiäsg\n",
      "===Diversity: 1.0 ===\n",
      "acc ioyrabrsryiluucdnzeurtik\n",
      "===Diversity: 1.2 ===\n",
      "accltassrtkluiliairfiarg\n",
      "ist\n",
      "Epoch 20/100\n",
      "13813600/13813600 [==============================] - 654s 47us/step - loss: 1.6907 - val_loss: 1.6925\n",
      "===Diversity: 0.2 ===\n",
      "acc \n",
      "odhtllasikvkkdka  eeähg\n",
      "===Diversity: 0.5 ===\n",
      "accl aurr cara3uvsokarrotgul\n",
      "===Diversity: 1.0 ===\n",
      "acc nilrftierijhsdkkigl pg\n",
      "w\n",
      "===Diversity: 1.2 ===\n",
      "accduodalhrltmllfalsiog iynl\n",
      "Epoch 21/100\n",
      "13813600/13813600 [==============================] - 654s 47us/step - loss: 1.6891 - val_loss: 1.6908\n",
      "===Diversity: 0.2 ===\n",
      "accr oltruisöekcakiecäpujnej\n",
      "===Diversity: 0.5 ===\n",
      "accdhoou\n",
      "\n",
      "altt\n",
      "cnynrtdu\n",
      "ahvl\n",
      "===Diversity: 1.0 ===\n",
      "accnteuariicc t\n",
      "tpivh\n",
      " oukhs\n",
      "===Diversity: 1.2 ===\n",
      "acc ionr\n",
      "plsligigkkirp\n",
      "jfzka\n",
      "Epoch 23/100\n",
      "13813600/13813600 [==============================] - 655s 47us/step - loss: 1.6884 - val_loss: 1.6901\n",
      "===Diversity: 0.2 ===\n",
      "accneolcrttgrskugagmzeukn8is\n",
      "===Diversity: 0.5 ===\n",
      "accrsho\n",
      "gla ibiwehmklrelrmvt\n",
      "===Diversity: 1.0 ===\n",
      "accneoidlrewj irmrjuaiigeka \n",
      "===Diversity: 1.2 ===\n",
      "acc koldigetgzr\n",
      "rtmeanria\n",
      "ak\n",
      "Epoch 24/100\n",
      "13813600/13813600 [==============================] - 654s 47us/step - loss: 1.6878 - val_loss: 1.6895\n",
      "===Diversity: 0.2 ===\n",
      "accneorltrlisrioau liiiuöhea\n",
      "===Diversity: 0.5 ===\n",
      "acclioldwiaa\n",
      "hkalgbukrmeeclg\n",
      "===Diversity: 1.0 ===\n",
      "acctkolafuvukyr7ar\n",
      "fuskwriar\n",
      "===Diversity: 1.2 ===\n",
      "accnherr\n",
      " rrujbiukaiieu\n",
      "iivp\n",
      "Epoch 25/100\n",
      "13813600/13813600 [==============================] - 654s 47us/step - loss: 1.6872 - val_loss: 1.6891\n",
      "===Diversity: 0.2 ===\n",
      "accukodlailrrki e\n",
      "llskvkvzli\n",
      "===Diversity: 0.5 ===\n",
      "accnheer\n",
      "ziitataibaigaisi\n",
      "ck\n",
      "===Diversity: 1.0 ===\n",
      "accyypluekadcusör u luiehluk\n",
      "===Diversity: 1.2 ===\n",
      "accleos igirzor\n",
      "kika\n",
      "\n",
      "glgrex\n",
      "Epoch 26/100\n",
      "13813600/13813600 [==============================] - 660s 48us/step - loss: 1.6866 - val_loss: 1.6889\n",
      "===Diversity: 0.2 ===\n",
      "acclcosug\n",
      "htlaeeileäkzikigpj\n",
      "===Diversity: 0.5 ===\n",
      "acc tolldbtnanitaepgpfrriura\n",
      "===Diversity: 1.0 ===\n",
      "accttaplrgikugzbkekpufsaklfr\n",
      "===Diversity: 1.2 ===\n",
      "accc alrndtgakiernggzjwäaole\n",
      "Epoch 27/100\n",
      "13813600/13813600 [==============================] - 654s 47us/step - loss: 1.6861 - val_loss: 1.6883\n",
      "===Diversity: 0.2 ===\n",
      "accttasjnuptotsekkqilijlejao\n",
      "===Diversity: 0.5 ===\n",
      "acclkalzprleeyinnmpmmskakkcb\n",
      "===Diversity: 1.0 ===\n",
      "accluodtcccpriygkiliirieikpr\n",
      "===Diversity: 1.2 ===\n",
      "accuaolrkirdlakörlgceisrzlkm\n",
      "Epoch 28/100\n",
      "13813600/13813600 [==============================] - 655s 47us/step - loss: 1.6856 - val_loss: 1.6875\n",
      "===Diversity: 0.2 ===\n",
      "acc\n",
      "aoilr sdrleaushoirpsrgaz\n",
      "===Diversity: 0.5 ===\n",
      "acc aou rr\n",
      "vjpaiiifcukc isap\n",
      "===Diversity: 1.0 ===\n",
      "acctho a eisarht laul uzllz\n",
      "\n",
      "===Diversity: 1.2 ===\n",
      "accntaptthghsbamlcoqinkluhil\n",
      "Epoch 29/100\n",
      "13813600/13813600 [==============================] - 655s 47us/step - loss: 1.6851 - val_loss: 1.6871\n",
      "===Diversity: 0.2 ===\n",
      "accgealt\n",
      "irsuteripudlkal enn\n",
      "===Diversity: 0.5 ===\n",
      "accsoodtkirvtruaueiigzogzz b\n",
      "===Diversity: 1.0 ===\n",
      "accvvebtoniugak ka\n",
      "ukjuxasks\n",
      "===Diversity: 1.2 ===\n",
      "accmialplngtjwll ills\n",
      "qa\n",
      "miu\n",
      "Epoch 30/100\n",
      "13813600/13813600 [==============================] - 654s 47us/step - loss: 1.6847 - val_loss: 1.6869\n",
      "===Diversity: 0.2 ===\n",
      "accllouaftsmktergnemsbvrszre\n",
      "===Diversity: 0.5 ===\n",
      "accree vu\n",
      "sk\n",
      "slnpayadplgiann\n",
      "===Diversity: 1.0 ===\n",
      "accucasrdjniäaztehakrentoäka\n",
      "===Diversity: 1.2 ===\n",
      "acctiolrmilein ekbisspkiueet\n",
      "Epoch 31/100\n",
      "13813600/13813600 [==============================] - 656s 48us/step - loss: 1.6842 - val_loss: 1.6864\n",
      "===Diversity: 0.2 ===\n",
      "accckonkcemuizhokflrg dkoisy\n",
      "===Diversity: 0.5 ===\n",
      "acc tilrieuagig isaiialutr\n",
      "a\n",
      "===Diversity: 1.0 ===\n",
      "accmt icv iklzel uheunbglabi\n",
      "===Diversity: 1.2 ===\n",
      "accrkadrmrnla\n",
      "a\n",
      "ne\n",
      "raen \n",
      "kji\n",
      "Epoch 32/100\n",
      "13813600/13813600 [==============================] - 651s 47us/step - loss: 1.6838 - val_loss: 1.6858\n",
      "===Diversity: 0.2 ===\n",
      "accnooatndtrear\n",
      "sjl alpvzl t\n",
      "===Diversity: 0.5 ===\n",
      "accdooertgkilkliapakgkij\n",
      "kxp\n",
      "===Diversity: 1.0 ===\n",
      "accntolpceiiealgsaaauyliripv\n",
      "===Diversity: 1.2 ===\n",
      "accgkidcl ylelhuiijluhlnella\n",
      "Epoch 33/100\n",
      "13813600/13813600 [==============================] - 652s 47us/step - loss: 1.6834 - val_loss: 1.6856\n",
      "===Diversity: 0.2 ===\n",
      "accraulmis tniishain armugka\n",
      "===Diversity: 0.5 ===\n",
      "accghiiurlgieritbzsyr tglaut\n",
      "===Diversity: 1.0 ===\n",
      "acclcasl rietewm\n",
      "agvhvealuui\n",
      "===Diversity: 1.2 ===\n",
      "accnholat\n",
      "sea\n",
      "zerzyeiitgpeiu\n",
      "Epoch 34/100\n",
      "13813600/13813600 [==============================] - 652s 47us/step - loss: 1.6831 - val_loss: 1.6852\n",
      "===Diversity: 0.2 ===\n",
      "acc iosaisrildakd\n",
      "adivayirsi\n",
      "===Diversity: 0.5 ===\n",
      "accn aua malai\n",
      "öiwecljrlkavg\n",
      "===Diversity: 1.0 ===\n",
      "acckyopjpbazcgkz lbkh vgkkrd\n",
      "===Diversity: 1.2 ===\n",
      "accuhuruajpiulirnlknc keklrx\n",
      "Epoch 35/100\n",
      "13813600/13813600 [==============================] - 652s 47us/step - loss: 1.6827 - val_loss: 1.6856\n",
      "===Diversity: 0.2 ===\n",
      "accs\n",
      "eictmu\n",
      "liuastzraazinigm\n",
      "===Diversity: 0.5 ===\n",
      "acc trdiclomldilis \n",
      "ums vzcn\n",
      "===Diversity: 1.0 ===\n",
      "accrialrduilirazaalzerlilaek\n",
      "===Diversity: 1.2 ===\n",
      "acclkevzlliiaaveiullhkukctup\n",
      "Epoch 36/100\n",
      "13813600/13813600 [==============================] - 659s 48us/step - loss: 1.6824 - val_loss: 1.6848\n",
      "===Diversity: 0.2 ===\n",
      "acctaojlrrpiesbrkakiaeloin\n",
      "r\n",
      "===Diversity: 0.5 ===\n",
      "accreolomaeisiigfee k\n",
      "sukdua\n",
      "===Diversity: 1.0 ===\n",
      "accneodrmslaiyi\n",
      "ue6k\n",
      "ulsllir\n",
      "===Diversity: 1.2 ===\n",
      "accrsdgisskssiioukil\n",
      "sial ea\n",
      "Epoch 37/100\n",
      "13813600/13813600 [==============================] - 656s 48us/step - loss: 1.6821 - val_loss: 1.6843\n",
      "===Diversity: 0.2 ===\n",
      "accl aducrkkkbsuiks kgigar\n",
      "i\n",
      "===Diversity: 0.5 ===\n",
      "accthr crlekz eepsszahiakkaf\n",
      "===Diversity: 1.0 ===\n",
      "accrmolaemcjruksgsglo lateuy\n",
      "===Diversity: 1.2 ===\n",
      "accfhuprrsaelietkcavaosi jkd\n",
      "Epoch 38/100\n",
      "13813600/13813600 [==============================] - 656s 47us/step - loss: 1.6818 - val_loss: 1.6841\n",
      "===Diversity: 0.2 ===\n",
      "accweolrrmrrlaraias uiltuu h\n",
      "===Diversity: 0.5 ===\n",
      "accihoiolluiaitiinaovalizrrk\n",
      "===Diversity: 1.0 ===\n",
      "accfkoltc\n",
      "rlsa\n",
      "arjiee\n",
      "zrsätj\n",
      "===Diversity: 1.2 ===\n",
      "accdtalu\n",
      "\n",
      "dvduilparlisdirsjm\n",
      "Epoch 39/100\n",
      "13813600/13813600 [==============================] - 656s 47us/step - loss: 1.6815 - val_loss: 1.6836\n",
      "===Diversity: 0.2 ===\n",
      "accnueefcsknglieiarrludrglar\n",
      "===Diversity: 0.5 ===\n",
      "acc\n",
      "hieurluslraitieiiöuklttl\n",
      "===Diversity: 1.0 ===\n",
      "accstaeigrdurkltt iegskakaee\n",
      "===Diversity: 1.2 ===\n",
      "acccieftz ilgkrioklqltleeaka\n",
      "Epoch 40/100\n",
      "13813600/13813600 [==============================] - 656s 47us/step - loss: 1.6812 - val_loss: 1.6835\n",
      "===Diversity: 0.2 ===\n",
      "accuoeuralaaat\n",
      "laukbuascripi\n",
      "===Diversity: 0.5 ===\n",
      "acctiploeataesmuukrb\n",
      "\n",
      "ilip\n",
      "e\n",
      "===Diversity: 1.0 ===\n",
      "accbhoordviileguicatjhaklgfg\n",
      "===Diversity: 1.2 ===\n",
      "accpehmiii iel uc\n",
      "flileterik\n",
      "Epoch 41/100\n",
      "13813600/13813600 [==============================] - 655s 47us/step - loss: 1.6809 - val_loss: 1.6833\n",
      "===Diversity: 0.2 ===\n",
      "acckiodl ermiurftiksuainpkir\n",
      "===Diversity: 0.5 ===\n",
      "acc\n",
      "yoer unt\n",
      "\n",
      "azuezurieimtas\n",
      "===Diversity: 1.0 ===\n",
      "accdhaeuitteeyaieanaial iatl\n",
      "===Diversity: 1.2 ===\n",
      "accfcoezg ucuihhkzde\n",
      "zcnstls\n",
      "Epoch 42/100\n",
      "13813600/13813600 [==============================] - 655s 47us/step - loss: 1.6807 - val_loss: 1.6828\n",
      "===Diversity: 0.2 ===\n",
      "accthaanceilkna a\n",
      "tuis\n",
      "ut\n",
      "sa\n",
      "===Diversity: 0.5 ===\n",
      "accktalricekxpulrjspe mif ia\n",
      "===Diversity: 1.0 ===\n",
      "accbsall\n",
      "\n",
      "reemuklaagaapi\n",
      "jay\n",
      "===Diversity: 1.2 ===\n",
      "acclyiiriitlguektzueilkaoiue\n",
      "Epoch 43/100\n",
      "13813600/13813600 [==============================] - 655s 47us/step - loss: 1.6804 - val_loss: 1.6823\n",
      "===Diversity: 0.2 ===\n",
      "accio lnr rax\n",
      "v\n",
      "\n",
      "saeuamugatj\n",
      "===Diversity: 0.5 ===\n",
      "acclthjlgclhauaa miezjiiiftk\n",
      "===Diversity: 1.0 ===\n",
      "accltoaltlauri is\n",
      "aig\n",
      "altlgu\n",
      "===Diversity: 1.2 ===\n",
      "accthrllioseaklseal luriirve\n",
      "Epoch 44/100\n",
      "13813600/13813600 [==============================] - 656s 47us/step - loss: 1.6802 - val_loss: 1.6822\n",
      "===Diversity: 0.2 ===\n",
      "accgioutnllilelfesekrstfhnrk\n",
      "===Diversity: 0.5 ===\n",
      "accpeicpliaclsesiltaktrmgwen\n",
      "===Diversity: 1.0 ===\n",
      "accd oswl\n",
      "hllkslljilkduxkzlj\n",
      "===Diversity: 1.2 ===\n",
      "accpaaltl \n",
      "galrutcfsyeicapla\n",
      "Epoch 45/100\n",
      "13813600/13813600 [==============================] - 657s 48us/step - loss: 1.6799 - val_loss: 1.6822\n",
      "===Diversity: 0.2 ===\n",
      "acc iiaerbneilhssiiroiuiezht\n",
      "===Diversity: 0.5 ===\n",
      "accnhoss\n",
      "alcuijiialkjlrrii s\n",
      "===Diversity: 1.0 ===\n",
      "accnionlrhyizslazln zlzltage\n",
      "===Diversity: 1.2 ===\n",
      "accdkhp l ikvlrlaahersijrene\n",
      "Epoch 46/100\n",
      "13813600/13813600 [==============================] - 660s 48us/step - loss: 1.6797 - val_loss: 1.6819\n",
      "===Diversity: 0.2 ===\n",
      "accnhodc alu li\n",
      "fgslpoagralt\n",
      "===Diversity: 0.5 ===\n",
      "accsnapliegusjlg iicbfend2gn\n",
      "===Diversity: 1.0 ===\n",
      "accriaurgilebtueluffkiarenku\n",
      "===Diversity: 1.2 ===\n",
      "accfh eli faifd znkirpasroal\n",
      "Epoch 47/100\n",
      "13813600/13813600 [==============================] - 656s 47us/step - loss: 1.6795 - val_loss: 1.6822\n",
      "===Diversity: 0.2 ===\n",
      "accltosaa gkteebaeippral eig\n",
      "===Diversity: 0.5 ===\n",
      "accnt ectntuies yk unoipieir\n",
      "===Diversity: 1.0 ===\n",
      "accches\n",
      "icto irusakiaioalsak\n",
      "===Diversity: 1.2 ===\n",
      "accqoaaw\n",
      "iihaegrelahlreailro\n",
      "Epoch 48/100\n",
      "13813600/13813600 [==============================] - 656s 48us/step - loss: 1.6793 - val_loss: 1.6815\n",
      "===Diversity: 0.2 ===\n",
      "accyhillcbailiyepl yet\n",
      "nbili\n",
      "===Diversity: 0.5 ===\n",
      "acc\n",
      "todc2cekkuej3ksui\n",
      "nlglsw\n",
      "===Diversity: 1.0 ===\n",
      "accstodaenyiielkeluitikljstl\n",
      "===Diversity: 1.2 ===\n",
      "accusadoi maipkndinukmvcxlie\n",
      "Epoch 49/100\n",
      "13813600/13813600 [==============================] - 657s 48us/step - loss: 1.6791 - val_loss: 1.6815\n",
      "===Diversity: 0.2 ===\n",
      "acc\n",
      "eoalntrliimkbsltouutaaai\n",
      "===Diversity: 0.5 ===\n",
      "accnaallazlurnksluede\n",
      "ooukak\n",
      "===Diversity: 1.0 ===\n",
      "acc eourihpgeopgrezwuv uvlzr\n",
      "===Diversity: 1.2 ===\n",
      "accthoslitkt p yiekrrsshzlir\n",
      "Epoch 50/100\n",
      "13813600/13813600 [==============================] - 656s 47us/step - loss: 1.6789 - val_loss: 1.6810\n",
      "===Diversity: 0.2 ===\n",
      "accvkait\n",
      "atioikiuujeitgumlrr\n",
      "===Diversity: 0.5 ===\n",
      "acc\n",
      "eoulkttlksuiiaphk isaeis\n",
      "===Diversity: 1.0 ===\n",
      "accscoelialdauie9aslibjoakhp\n",
      "===Diversity: 1.2 ===\n",
      "accttapl hselu selayfkaaaikb\n",
      "Epoch 51/100\n",
      "13813600/13813600 [==============================] - 656s 47us/step - loss: 1.6787 - val_loss: 1.6809\n",
      "===Diversity: 0.2 ===\n",
      "accshogliriiiijiirfiscsllumj\n",
      "===Diversity: 0.5 ===\n",
      "accdtedtkiaitaikullpataugrri\n",
      "===Diversity: 1.0 ===\n",
      "acci osdiklk\n",
      "fielamiuuktraet\n",
      "===Diversity: 1.2 ===\n",
      "accueourrveillsalglkaaku\n",
      "hap\n",
      "Epoch 52/100\n",
      "13813600/13813600 [==============================] - 657s 48us/step - loss: 1.6785 - val_loss: 1.6810\n",
      "===Diversity: 0.2 ===\n",
      "acclkeliblrlkank\n",
      "eiehi\n",
      "zipra\n",
      "===Diversity: 0.5 ===\n",
      "acct\n",
      "allti\n",
      "nssztdarhkpkakrle\n",
      "===Diversity: 1.0 ===\n",
      "accneeptllllleeosbratilacaiä\n",
      "===Diversity: 1.2 ===\n",
      "accih actcrc aztdskit jze\n",
      "si\n",
      "Epoch 53/100\n",
      "13813600/13813600 [==============================] - 656s 47us/step - loss: 1.6783 - val_loss: 1.6809\n",
      "===Diversity: 0.2 ===\n",
      "accvtiull eaugekaexklsklcmmi\n",
      "===Diversity: 0.5 ===\n",
      "acctc dr laetlrfatilapiereug\n",
      "===Diversity: 1.0 ===\n",
      "accgti t  itkiki tiuarlu aih\n",
      "===Diversity: 1.2 ===\n",
      "accmioaneleagrlnijndafgasdg \n",
      "Epoch 54/100\n",
      "13813600/13813600 [==============================] - 656s 47us/step - loss: 1.6782 - val_loss: 1.6803\n",
      "===Diversity: 0.2 ===\n",
      "accriucl\n",
      "ismjuisl\n",
      "ksuiu lkal\n",
      "===Diversity: 0.5 ===\n",
      "accdipacliapkklmediiiezs uic\n",
      "===Diversity: 1.0 ===\n",
      "accfkildpv\n",
      "paag\n",
      "irsrdrkirjdt\n",
      "===Diversity: 1.2 ===\n",
      "acc holrjlivirailziybscal\n",
      "lr\n",
      "Epoch 55/100\n",
      "13813600/13813600 [==============================] - 657s 48us/step - loss: 1.6780 - val_loss: 1.6800\n",
      "===Diversity: 0.2 ===\n",
      "acc collilrmhi uzlazinllkaig\n",
      "===Diversity: 0.5 ===\n",
      "accltou t yletne\n",
      "iurmarcjeas\n",
      "===Diversity: 1.0 ===\n",
      "accdoosl\n",
      "ziacelcnlgj eiorurk\n",
      "===Diversity: 1.2 ===\n",
      "accgisa lcallahrllftsloiigrr\n",
      "Epoch 56/100\n",
      "13813600/13813600 [==============================] - 657s 48us/step - loss: 1.6778 - val_loss: 1.6804\n",
      "===Diversity: 0.2 ===\n",
      "accreodtyresgrirralks\n",
      "hruole\n",
      "===Diversity: 0.5 ===\n",
      "accltoenisarlbtialleliaaaidm\n",
      "===Diversity: 1.0 ===\n",
      "accnhluurskvrnkeeuuakbtcisi \n",
      "===Diversity: 1.2 ===\n",
      "accgtouiieeasealuyszivrailkk\n",
      "Epoch 57/100\n",
      "13813600/13813600 [==============================] - 657s 48us/step - loss: 1.6777 - val_loss: 1.6798\n",
      "===Diversity: 0.2 ===\n",
      "accmhednttliialrlekin gheiel\n",
      "===Diversity: 0.5 ===\n",
      "accvaooahigaub\n",
      " ikamillkkikz\n",
      "===Diversity: 1.0 ===\n",
      "accreoiirircdueigiuaersmhoaa\n",
      "===Diversity: 1.2 ===\n",
      "accth ueil2irasrleilzlaverep\n",
      "Epoch 58/100\n",
      "13813600/13813600 [==============================] - 656s 48us/step - loss: 1.6775 - val_loss: 1.6799\n",
      "===Diversity: 0.2 ===\n",
      "accneoilf ueejip leakiikfbf\n",
      "\n",
      "===Diversity: 0.5 ===\n",
      "accleodl\n",
      "tiieaahz  lidturhli\n",
      "===Diversity: 1.0 ===\n",
      "accntedttllresolssrbi\n",
      "n\n",
      "mazs\n",
      "===Diversity: 1.2 ===\n",
      "accperdaty\n",
      "g\n",
      "eltl nrcaseer\n",
      "o\n",
      "Epoch 59/100\n",
      "13813600/13813600 [==============================] - 657s 48us/step - loss: 1.6774 - val_loss: 1.6798\n",
      "===Diversity: 0.2 ===\n",
      "accrioaliiisaeahamalssmatlnp\n",
      "===Diversity: 0.5 ===\n",
      "acc\n",
      "oalrllksslnutalluzevl\n",
      "lt\n",
      "===Diversity: 1.0 ===\n",
      "accahiltgeppiuaoiskiryauiåij\n",
      "===Diversity: 1.2 ===\n",
      "accttollierye ick lanualuatg\n",
      "Epoch 60/100\n",
      "13813600/13813600 [==============================] - 656s 48us/step - loss: 1.6772 - val_loss: 1.6794\n",
      "===Diversity: 0.2 ===\n",
      "accstililerai\n",
      "irlzkztijxials\n",
      "===Diversity: 0.5 ===\n",
      "accuhosarlniiaziasas pcg slf\n",
      "===Diversity: 1.0 ===\n",
      "accrhalppiir\n",
      "liia oaoekkyies\n",
      "===Diversity: 1.2 ===\n",
      "acctkouainulcjuamkbczrrllok\n",
      "\n",
      "Epoch 61/100\n",
      "13813600/13813600 [==============================] - 656s 48us/step - loss: 1.6771 - val_loss: 1.6791\n",
      "===Diversity: 0.2 ===\n",
      "accskanagatpnift\n",
      "uvyaar gver\n",
      "===Diversity: 0.5 ===\n",
      "acctsinaitekv nieabkefeigisz\n",
      "===Diversity: 1.0 ===\n",
      "acczkoiwrecblkokeauenezmlada\n",
      "===Diversity: 1.2 ===\n",
      "accneoprllsouenhijrklsii\n",
      "\n",
      "gi\n",
      "Epoch 62/100\n",
      "13813600/13813600 [==============================] - 662s 48us/step - loss: 1.6769 - val_loss: 1.6794\n",
      "===Diversity: 0.2 ===\n",
      "accseopcllcireilfrlalf\n",
      "kiva \n",
      "===Diversity: 0.5 ===\n",
      "acc\n",
      "keltieaalmao vrsnifussul\n",
      "===Diversity: 1.0 ===\n",
      "accneolallllaiiipieszmaciczi\n",
      "===Diversity: 1.2 ===\n",
      "accciedzlsriraaaudeialseaje\n",
      "\n",
      "Epoch 63/100\n",
      "13813600/13813600 [==============================] - 653s 47us/step - loss: 1.6768 - val_loss: 1.6792\n",
      "===Diversity: 0.2 ===\n",
      "acctteurillllemilrmkarmsrjar\n",
      "===Diversity: 0.5 ===\n",
      "acc\n",
      "hlsleb jllsjspci dtouizg\n",
      "===Diversity: 1.0 ===\n",
      "acci oaeicnanziiiihjflauilei\n",
      "===Diversity: 1.2 ===\n",
      "accbcortiiaoikntzpa1mh jrejs\n",
      "Epoch 64/100\n",
      "13813600/13813600 [==============================] - 655s 47us/step - loss: 1.6767 - val_loss: 1.6791\n",
      "===Diversity: 0.2 ===\n",
      "accrhodcilal zgjauvltss\n",
      "l\n",
      "si\n",
      "===Diversity: 0.5 ===\n",
      "accukouligeaapareickailytsni\n",
      "===Diversity: 1.0 ===\n",
      "acc tosbegaytkleeer\n",
      "kegsnmyf\n",
      "===Diversity: 1.2 ===\n",
      "accrhelli pai imiskiäkz\n",
      "etue\n",
      "Epoch 65/100\n",
      "13813600/13813600 [==============================] - 655s 47us/step - loss: 1.6765 - val_loss: 1.6790\n",
      "===Diversity: 0.2 ===\n",
      "accmkos\n",
      "nr ieselpaakitraajq\n",
      "\n",
      "===Diversity: 0.5 ===\n",
      "accchulnieeenazsnfkekaskegat\n",
      "===Diversity: 1.0 ===\n",
      "accmmoaaitiweilwytaaeaskn\n",
      "iu\n",
      "===Diversity: 1.2 ===\n",
      "accthollrlnsialklaeekkailis\n",
      "\n",
      "Epoch 66/100\n",
      "13813600/13813600 [==============================] - 653s 47us/step - loss: 1.6764 - val_loss: 1.6789\n",
      "===Diversity: 0.2 ===\n",
      "accvkrnolg jis\n",
      "tna\n",
      "idiaplsii\n",
      "===Diversity: 0.5 ===\n",
      "acc\n",
      "ted\n",
      "lbis sllsgikmbeiimal\n",
      "===Diversity: 1.0 ===\n",
      "acc iodlpikkgw\n",
      "k eiilgewkzzt\n",
      "===Diversity: 1.2 ===\n",
      "accntoagaaiclsuiuepnciseak8a\n",
      "Epoch 67/100\n",
      "13813600/13813600 [==============================] - 654s 47us/step - loss: 1.6763 - val_loss: 1.6789\n",
      "===Diversity: 0.2 ===\n",
      "acctholygle nft\n",
      "lrraaqamwujm\n",
      "===Diversity: 0.5 ===\n",
      "accnae anx\n",
      "laåathiieo\n",
      "tkkmie\n",
      "===Diversity: 1.0 ===\n",
      "accsaolezrctara\n",
      "nhdpuiher5\n",
      "m\n",
      "===Diversity: 1.2 ===\n",
      "accckollii\n",
      "isakssu\n",
      "iinei\n",
      "lli\n",
      "Epoch 68/100\n",
      "13813600/13813600 [==============================] - 654s 47us/step - loss: 1.6762 - val_loss: 1.6783\n",
      "===Diversity: 0.2 ===\n",
      "accbiodiiileruukklespaaosrii\n",
      "===Diversity: 0.5 ===\n",
      "acctridilait\n",
      "oreacbiiösbckbh\n",
      "===Diversity: 1.0 ===\n",
      "acclooialinisnkiraehnltminse\n",
      "===Diversity: 1.2 ===\n",
      "accntelaalieaylaawloinnppluh\n",
      "Epoch 69/100\n",
      "13813600/13813600 [==============================] - 656s 47us/step - loss: 1.6761 - val_loss: 1.6783\n",
      "===Diversity: 0.2 ===\n",
      "accntepcpciklihaeiblz\n",
      "vlekze\n",
      "===Diversity: 0.5 ===\n",
      "accieoalvi gzi mruzunapkpmkr\n",
      "===Diversity: 1.0 ===\n",
      "accr op gnirczilgaaoa\n",
      "loiier\n",
      "===Diversity: 1.2 ===\n",
      "acc sodcrple stcagltiakieles\n",
      "Epoch 70/100\n",
      "13813600/13813600 [==============================] - 654s 47us/step - loss: 1.6760 - val_loss: 1.6789\n",
      "===Diversity: 0.2 ===\n",
      "accbiolailrigruiterdfuocgktu\n",
      "===Diversity: 0.5 ===\n",
      "accneadyisaygsleltjralogua\n",
      "e\n",
      "===Diversity: 1.0 ===\n",
      "acc\n",
      "eod\n",
      "ibaieaeee\n",
      "killeiltnl\n",
      "===Diversity: 1.2 ===\n",
      "acc\n",
      "kapalijiaaaedaiu oi\n",
      "eärh\n",
      "Epoch 71/100\n",
      "13813600/13813600 [==============================] - 654s 47us/step - loss: 1.6758 - val_loss: 1.6782\n",
      "===Diversity: 0.2 ===\n",
      "accthalaici iteriesshlsnridk\n",
      "===Diversity: 0.5 ===\n",
      "acclereill\n",
      "oiearrerlieylsune\n",
      "===Diversity: 1.0 ===\n",
      "acc \n",
      "oapitiria\n",
      "tge iimeajfie\n",
      "===Diversity: 1.2 ===\n",
      "acctkolougzc\n",
      "brrsmihsukilek \n",
      "Epoch 72/100\n",
      "13813600/13813600 [==============================] - 655s 47us/step - loss: 1.6757 - val_loss: 1.6779\n",
      "===Diversity: 0.2 ===\n",
      "acc\n",
      "houlijr ihree\n",
      "i\n",
      "lglgreer\n",
      "===Diversity: 0.5 ===\n",
      "accgoodiflsgrevjklhmika slni\n",
      "===Diversity: 1.0 ===\n",
      "acc\n",
      "iauleum e\n",
      "mmelrnklntkaan\n",
      "===Diversity: 1.2 ===\n",
      "accctoieeie fuilaklikkk hfas\n",
      "Epoch 73/100\n",
      "13813600/13813600 [==============================] - 655s 47us/step - loss: 1.6756 - val_loss: 1.6780\n",
      "===Diversity: 0.2 ===\n",
      "accmheslvlseua teckagr irs\n",
      "l\n",
      "===Diversity: 0.5 ===\n",
      "accp\n",
      "ourokslelrvtsirkkreeeio\n",
      "===Diversity: 1.0 ===\n",
      "acct idrlctgslua l klr\n",
      "lknui\n",
      "===Diversity: 1.2 ===\n",
      "acclaauuuitt rl ecllrzheaedg\n",
      "Epoch 74/100\n",
      "13813600/13813600 [==============================] - 661s 48us/step - loss: 1.6755 - val_loss: 1.6780\n",
      "===Diversity: 0.2 ===\n",
      "acc hadnceiiuanpr\n",
      "arlekenena\n",
      "===Diversity: 0.5 ===\n",
      "accs oiui\n",
      "alalinlrciald\n",
      "zrne\n",
      "===Diversity: 1.0 ===\n",
      "accduolaicrpöblameggckhunzku\n",
      "===Diversity: 1.2 ===\n",
      "acctrairigsiulehdcliuss\n",
      "iylv\n",
      "Epoch 75/100\n",
      " 3026944/13813600 [=====>........................] - ETA: 8:10 - loss: 1.6756"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-44a48ef607d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"adam\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mhistory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4096\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprint_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3727\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3729\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \"\"\"\n\u001b[0;32m-> 1551\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1591\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1593\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=\"adam\")\n",
    "\n",
    "history=model.fit(X, Y, batch_size=4096, validation_split=0.1,  epochs=100, shuffle=True, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"alltext.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Per name model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103139\n",
      "reilamex oy\n",
      "kalakaapu oy\n",
      "metlab oy\n",
      "vuorinvest oy\n",
      "martinkari oy\n",
      "sähköjänis oy\n",
      "oy klismos ab\n",
      "leka global oy\n",
      "bosom oy\n",
      "vhl huolto oy\n"
     ]
    }
   ],
   "source": [
    "import json \n",
    "import random\n",
    "#finnish_companies = json.load(open(\"finnish_kaggle_companies.json\",\"r+\"))\n",
    "\n",
    "Tx=15\n",
    "\n",
    "# finnish \n",
    "finnish_names_arr=[normalize_text(company) for company in finnish_companies if len(company)<Tx]\n",
    "random.shuffle(finnish_names_arr)\n",
    "finnish_names_text=\"\".join(finnish_names_arr)\n",
    "\n",
    "# all companies \n",
    "#names_arr=[normalize_text(company) for company in all_companies if len(company)<Tx]\n",
    "#random.shuffle(names_arr)\n",
    "#names_arr=random.choices(names_arr,k=int(len(finnish_names_arr)))\n",
    "#finnish_names_arr+=names_arr\n",
    "\n",
    "\n",
    "characters=sorted(list(set(finnish_names_text)))\n",
    "characters=[\".\",\"E\"]+characters # . is none, E is end of line\n",
    "char_indices = dict((c, i) for i, c in enumerate(characters))\n",
    "indices_char = dict((i, c) for i, c in enumerate(characters))\n",
    "\n",
    "print(len(finnish_names_arr))\n",
    "print(\"\\n\".join(random.choices(finnish_names_arr,k=10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/103139 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  6%|▌         | 6122/103139 [00:00<00:01, 61212.91it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 12%|█▏        | 12813/103139 [00:00<00:01, 62812.49it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 19%|█▉        | 19591/103139 [00:00<00:01, 64222.02it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 26%|██▌       | 26564/103139 [00:00<00:01, 65780.45it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 32%|███▏      | 33042/103139 [00:00<00:01, 65474.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 39%|███▊      | 39763/103139 [00:00<00:00, 65983.77it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 45%|████▌     | 46559/103139 [00:00<00:00, 66562.71it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 52%|█████▏    | 53492/103139 [00:00<00:00, 67368.32it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 58%|█████▊    | 59885/103139 [00:00<00:00, 64481.81it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 65%|██████▍   | 66742/103139 [00:01<00:00, 65654.73it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 72%|███████▏  | 73798/103139 [00:01<00:00, 67051.96it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 78%|███████▊  | 80841/103139 [00:01<00:00, 68027.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 85%|████████▌ | 87932/103139 [00:01<00:00, 68867.34it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 92%|█████████▏| 94973/103139 [00:01<00:00, 69322.96it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 103139/103139 [00:01<00:00, 67376.91it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((103139, 15, 42), (103139, 15, 42))"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def vectorization(words, n_x, Tx=None):\n",
    "    \"\"\"\n",
    "    Convert X and Y (lists) into arrays to be given to a recurrent neural network.\n",
    "    \n",
    "    Arguments:\n",
    "    X -- \n",
    "    Y -- \n",
    "    Tx -- integer, sequence length\n",
    "    \n",
    "    Returns:\n",
    "    x -- array of shape (m, Tx, len(chars))\n",
    "    y -- array of shape (m, Tx, len(chars))\n",
    "    \"\"\"\n",
    "    if Tx is None:\n",
    "        Tx=len(max(words,key=len))\n",
    "        print(Tx)\n",
    "    \n",
    "    m = len(words)\n",
    "    x = np.zeros((m, Tx, n_x), dtype=np.bool)\n",
    "    y = np.zeros((m, Tx, n_x), dtype=np.bool)\n",
    "    \n",
    "    for w, word in enumerate(tqdm(words)):\n",
    "        word=word[:Tx]\n",
    "        x[w, 0:len(word)+1, :] = str_to_vec(word,start_with_null=True)\n",
    "        x[w, len(word)+1:, char_indices[\"E\"]] = 1\n",
    "        \n",
    "        y[w, 0:len(word),:] = str_to_vec(word)\n",
    "        y[w, len(word):, char_indices[\"E\"]] = 1\n",
    "        \n",
    "    return x, y \n",
    "\n",
    "Xf,Yf=vectorization(finnish_names_arr, n_x=len(characters), Tx=Tx)\n",
    "Xf.shape, Yf.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".ninra oyEEEEEE\n",
      "ninra oyEEEEEEE\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(vec_to_str(Xf[11324])),\n",
    "print(vec_to_str(Yf[11324]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kyrpä.......... -> elää rktoaEEEEE -> k\n",
      "kyrpäk......... -> elää iioaaEEEEE -> i\n",
      "kyrpäki........ -> elää i tooEEEEE -> v\n",
      "kyrpäkiv....... -> elää i eooEEEEE -> o\n",
      "kyrpäkivo...... -> elää i e  aEEEE ->  \n",
      "kyrpäkivo ..... -> elää i e obEEEE -> o\n",
      "kyrpäkivo o.... -> elää i e oyEEEE -> y\n",
      "kyrpäkivo oy... -> elää i e oyEEEE -> E\n",
      "kyrpäkivo oy\n"
     ]
    }
   ],
   "source": [
    "def make_name(model, beginning=\"\"):\n",
    "    name = beginning\n",
    "    x = np.zeros((1, Tx, len(characters)))\n",
    "    x[0,0:len(beginning),:]=str_to_vec(beginning)\n",
    "    \n",
    "    for i in range(len(beginning)-1,Tx-1):\n",
    "        prediction=model.predict(x)[0]\n",
    "        probs = list(prediction[i])\n",
    "        probs = probs / np.sum(probs)\n",
    "        index = np.random.choice(range(len(characters)), p=probs)\n",
    "        #index = np.argmax(probs)\n",
    "        character = indices_char[index]\n",
    "        print(f\"{vec_to_str(x[0])} -> {vec_to_str(prediction)} -> {character}\")\n",
    "        if character==\"E\":\n",
    "            break\n",
    "        name+=character\n",
    "        x[0, i+1, index] = 1\n",
    "\n",
    "        i += 1\n",
    "    \n",
    "    print(name)\n",
    "\n",
    "for i in range\n",
    "make_name(model,\"kyrpä\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_33 (LSTM)               (None, 15, 64)            27392     \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 15, 42)            2730      \n",
      "=================================================================\n",
      "Total params: 30,122\n",
      "Trainable params: 30,122\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers, models\n",
    "from keras.layers import Dense, Input, LSTM,GRU\n",
    "\n",
    "drp=0\n",
    "model=models.Sequential()\n",
    "model.add(LSTM(64, input_shape=(Tx, len(characters)),return_sequences=True))\n",
    "model.add(Dense(len(characters),activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import LambdaCallback\n",
    "\n",
    "def on_epoch_end(epoch, logs):\n",
    "    for i in range(3):\n",
    "        make_name(model)\n",
    "        \n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 92825 samples, validate on 10314 samples\n",
      "Epoch 1/1000\n",
      "92825/92825 [==============================] - 2s 25us/step - loss: 2.0997 - val_loss: 2.0806\n",
      "t8oese ra boa\n",
      "ä3a0 opy duo \n",
      "zl0kef\n",
      "Epoch 2/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 2.0622 - val_loss: 2.0439\n",
      "göcmari al oo\n",
      "7arxs yy\n",
      "xje nuont moo\n",
      "Epoch 3/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 2.0279 - val_loss: 2.0106\n",
      "hwl1ötn of\n",
      "ä7sd7aaal mlyy\n",
      "drmamapo ox\n",
      "Epoch 4/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.9954 - val_loss: 1.9789\n",
      "3\n",
      "özaor s  yy\n",
      "pmkinno wi \n",
      "Epoch 5/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.9639 - val_loss: 1.9479\n",
      "m5ioiilayl\n",
      "bnlvuotarayoy\n",
      "jtesa3rea  \n",
      "Epoch 6/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.9330 - val_loss: 1.9172\n",
      "j4e oöiruayvoy\n",
      "pcvakopoiycy\n",
      "viia9kcoucay \n",
      "Epoch 7/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.9025 - val_loss: 1.8871\n",
      "öntarit oy\n",
      "h6aralta f oy\n",
      "uthgopra n yy\n",
      "Epoch 8/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.8726 - val_loss: 1.8578\n",
      "hdpb n oyo\n",
      "lkiracn or u o\n",
      "3 rka ollpiil \n",
      "Epoch 9/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.8437 - val_loss: 1.8297\n",
      "i0lasenomyyb\n",
      "qd pisesmioo\n",
      "scareknötoy\n",
      "Epoch 10/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.8162 - val_loss: 1.8033\n",
      "nb4oaji oy\n",
      "\n",
      " abm  krot ayl\n",
      "Epoch 11/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.7907 - val_loss: 1.7791\n",
      "x aobd  oy\n",
      " yg j yjrantte\n",
      "jtme oy\n",
      "Epoch 12/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.7674 - val_loss: 1.7574\n",
      "u inoait oy\n",
      "o1yanso gm o\n",
      "tsoils oy\n",
      "Epoch 13/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.7468 - val_loss: 1.7384\n",
      "jraanid oy\n",
      "vi om\n",
      "etidle ttoo oy\n",
      "Epoch 14/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.7287 - val_loss: 1.7219\n",
      "4parateso oy\n",
      "ckiasek oy\n",
      "öfontel a oy\n",
      "Epoch 15/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.7130 - val_loss: 1.7076\n",
      ".evi  iy\n",
      "taldiinocoyy\n",
      "fkteiforoda oy\n",
      "Epoch 16/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.6995 - val_loss: 1.6950\n",
      "7 kkkcimoyje o\n",
      "öxka oydel  y\n",
      "gouurpuprn oy\n",
      "Epoch 17/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.6873 - val_loss: 1.6839\n",
      "hhinauk oy\n",
      "qpaaas oy\n",
      "ncekewo  y\n",
      "Epoch 18/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.6765 - val_loss: 1.6738\n",
      "lpruutinn oy\n",
      "o yed snqab\n",
      "ölsa fifto yy\n",
      "Epoch 19/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.6666 - val_loss: 1.6644\n",
      "dlilar oy\n",
      "jashi\n",
      "cxtilius oy\n",
      "Epoch 20/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.6574 - val_loss: 1.6557\n",
      "9enuoa ob\n",
      "iletgre oy\n",
      "brilkito oy\n",
      "Epoch 21/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.6487 - val_loss: 1.6475\n",
      "obc ran oy\n",
      "ecttrati oy\n",
      "uptinopousa oy\n",
      "Epoch 22/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.6408 - val_loss: 1.6399\n",
      "cantk  om\n",
      "fuurali oy\n",
      "gntaorja oy\n",
      "Epoch 23/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.6331 - val_loss: 1.6327\n",
      "inaveymi r ob\n",
      "futreriu oy\n",
      "29t oy\n",
      "Epoch 24/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.6258 - val_loss: 1.6258\n",
      "5suvugac oy\n",
      "vanoumesa oy\n",
      "ha filuaurru o\n",
      "Epoch 25/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.6189 - val_loss: 1.6194\n",
      "pde oynne oy\n",
      "wansomigo oy\n",
      "y\n",
      "Epoch 26/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.6124 - val_loss: 1.6132\n",
      "lm pek oy\n",
      "twal umalt oy\n",
      "memanaka oy\n",
      "Epoch 27/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.6063 - val_loss: 1.6074\n",
      "jopicasä oy\n",
      "4kogix oy\n",
      " cagror abl\n",
      "Epoch 28/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.6003 - val_loss: 1.6018\n",
      "vkj sumi  oy\n",
      "edme oy\n",
      "rje lelone oy\n",
      "Epoch 29/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.5947 - val_loss: 1.5965\n",
      " tosicon koy\n",
      "7nverehiin oy\n",
      "gredypuo oy\n",
      "Epoch 30/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.5894 - val_loss: 1.5914\n",
      "edn onwel oy\n",
      "epitetu oy\n",
      "adelns oy\n",
      "Epoch 31/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.5843 - val_loss: 1.5865\n",
      "rintenno eul o\n",
      "oinnals oy\n",
      "0wliverm oy\n",
      "Epoch 32/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.5794 - val_loss: 1.5819\n",
      "estelpont oy\n",
      "8veti ahti oy\n",
      "jäkebias oy\n",
      "Epoch 33/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.5748 - val_loss: 1.5775\n",
      "himer oy\n",
      "kkolis lyo db\n",
      "\n",
      "Epoch 34/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.5704 - val_loss: 1.5732\n",
      "mhali oy\n",
      "cholnawäh äb\n",
      "rtijat ab\n",
      "Epoch 35/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.5661 - val_loss: 1.5692\n",
      "24sraon oy\n",
      "i os oydateb\n",
      "maämi oy\n",
      "Epoch 36/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.5621 - val_loss: 1.5655\n",
      "4y pukoseaob o\n",
      "vipo ob\n",
      "helitome oy\n",
      "Epoch 37/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.5582 - val_loss: 1.5614\n",
      "3teraxe oy\n",
      "6jy puret oy\n",
      "sahtaka oy\n",
      "Epoch 38/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.5543 - val_loss: 1.5579\n",
      "larilan oy\n",
      "udigl oy\n",
      "kolmetic oy\n",
      "Epoch 39/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.5508 - val_loss: 1.5543\n",
      "30g oy\n",
      "lavanot oy\n",
      "evu erat oy\n",
      "Epoch 40/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.5474 - val_loss: 1.5510\n",
      "ezponnd oy\n",
      "atratoi oy\n",
      "oyåemny la\n",
      "Epoch 41/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.5439 - val_loss: 1.5481\n",
      "nzam oy\n",
      "crasiuc oy\n",
      "8xyt oy\n",
      "Epoch 42/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.5407 - val_loss: 1.5447\n",
      "92hecap oy\n",
      "12abzor oy\n",
      "astama rod\n",
      "Epoch 43/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.5376 - val_loss: 1.5418\n",
      "terdwad ta oy\n",
      "bbenger oy\n",
      "5a valel oy\n",
      "Epoch 44/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.5346 - val_loss: 1.5389\n",
      "graives oy\n",
      "icanb oy\n",
      "åafk oy\n",
      "Epoch 45/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.5318 - val_loss: 1.5363\n",
      "uingonal oy\n",
      "p selle oy\n",
      "tdos becco oy\n",
      "Epoch 46/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.5291 - val_loss: 1.5335\n",
      "xuri oy\n",
      "ojupeest oy\n",
      "jprcrs oy\n",
      "Epoch 47/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.5263 - val_loss: 1.5308\n",
      "åferib oy\n",
      ".nde fella oy\n",
      "hdi hitä oy\n",
      "Epoch 48/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.5237 - val_loss: 1.5283\n",
      "mroni oy\n",
      "ykwoöaso oy\n",
      "ewlas oy\n",
      "Epoch 49/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.5213 - val_loss: 1.5258\n",
      "skopa grone oy\n",
      "veunoat oy\n",
      ".raclob oy\n",
      "Epoch 50/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.5188 - val_loss: 1.5235\n",
      "fillcon or\n",
      "voistone oy\n",
      "tforpint oy\n",
      "Epoch 51/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.5164 - val_loss: 1.5215\n",
      "fba toma oy\n",
      "30becaro oy\n",
      "\n",
      "Epoch 52/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.5142 - val_loss: 1.5192\n",
      "elipora oy\n",
      "jartecun oy\n",
      "houn oy\n",
      "Epoch 53/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.5122 - val_loss: 1.5169\n",
      "navevart oy\n",
      "o feretog oy\n",
      "qvitama oy\n",
      "Epoch 54/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.5100 - val_loss: 1.5149\n",
      "sv oy\n",
      "lidogc oy\n",
      "ankelon oy\n",
      "Epoch 55/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.5079 - val_loss: 1.5129\n",
      "4zy oy\n",
      "tos oy\n",
      "mgesä joy oy\n",
      "Epoch 56/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.5059 - val_loss: 1.5110\n",
      "vilel oy\n",
      "hle tanvico oy\n",
      "fecdeowoi oy\n",
      "Epoch 57/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.5039 - val_loss: 1.5093\n",
      "jpom 9 oy\n",
      "sdapaboo oy\n",
      "olomast oy\n",
      "Epoch 58/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.5021 - val_loss: 1.5074\n",
      "m6 ravig oy\n",
      "årer oy\n",
      "roy satin \n",
      "Epoch 59/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.5002 - val_loss: 1.5056\n",
      "voritoi oy\n",
      "treka pe oy\n",
      "zgo foldas gb\n",
      "Epoch 60/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4985 - val_loss: 1.5037\n",
      "fonrtiet oy\n",
      "kallieta oy\n",
      "zostiam oy\n",
      "Epoch 61/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4968 - val_loss: 1.5022\n",
      "mon steesau oy\n",
      "centa ret oy\n",
      "jl tymöt oy\n",
      "Epoch 62/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4950 - val_loss: 1.5008\n",
      "aradur oy\n",
      "2båhdex oy\n",
      "nu give oy\n",
      "Epoch 63/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4935 - val_loss: 1.4988\n",
      "gilot oy\n",
      "agkot on\n",
      "qkpaivec oy\n",
      "Epoch 64/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4918 - val_loss: 1.4973\n",
      "pp kaini oy\n",
      "pubaricg oy\n",
      "qy altisab\n",
      "Epoch 65/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4902 - val_loss: 1.4959\n",
      "aj kskksk oy\n",
      "aru oy\n",
      "bootdet oy\n",
      "Epoch 66/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4888 - val_loss: 1.4943\n",
      "clost oy\n",
      " cemarica oy\n",
      "neste od\n",
      "Epoch 67/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4873 - val_loss: 1.4928\n",
      "galsa oy\n",
      "284 sut oy\n",
      "oy\n",
      "Epoch 68/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4858 - val_loss: 1.4912\n",
      "ndanica oy\n",
      "qmecob oy\n",
      "dec dy lfspoa\n",
      "Epoch 69/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4842 - val_loss: 1.4899\n",
      "comarin oy\n",
      "pivaco oy\n",
      "ulid so \n",
      "Epoch 70/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4828 - val_loss: 1.4886\n",
      "q unjaite oy\n",
      "retojex oy\n",
      "24 oy\n",
      "Epoch 71/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4815 - val_loss: 1.4874\n",
      "etta boy llc\n",
      "pronsa oy\n",
      "bitratart oy\n",
      "Epoch 72/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4804 - val_loss: 1.4866\n",
      "unoj ias oy\n",
      "xon oy\n",
      "8 feradas oy\n",
      "Epoch 73/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4790 - val_loss: 1.4846\n",
      "catiplo oy\n",
      "qrant ab\n",
      "beons oy\n",
      "Epoch 74/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4775 - val_loss: 1.4833\n",
      "tästespuo oy\n",
      "one htoke ly\n",
      "ämst sifit oy\n",
      "Epoch 75/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4764 - val_loss: 1.4823\n",
      "tkus oy\n",
      "henat oy\n",
      "tewid oy\n",
      "Epoch 76/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4752 - val_loss: 1.4809\n",
      "ilengre oy\n",
      "foset oy\n",
      "ånelen std ab\n",
      "Epoch 77/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4738 - val_loss: 1.4796\n",
      "fregmoy lad\n",
      "bod ab\n",
      "tgroax oy\n",
      "Epoch 78/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4725 - val_loss: 1.4784\n",
      "selecar oy\n",
      "stwall oy\n",
      "rj mere oy\n",
      "Epoch 79/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4714 - val_loss: 1.4773\n",
      "acst oy\n",
      "hteste oy\n",
      "skohussors oy\n",
      "Epoch 80/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4702 - val_loss: 1.4761\n",
      "ilaa oy\n",
      "amate 1 oy\n",
      "gel sa oy\n",
      "Epoch 81/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4691 - val_loss: 1.4750\n",
      "ete oy\n",
      "madeco oy\n",
      "rd cepite oy\n",
      "Epoch 82/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4681 - val_loss: 1.4740\n",
      "66z\n",
      "ääk oy\n",
      "kendar oy\n",
      "Epoch 83/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4669 - val_loss: 1.4727\n",
      "oipto oy\n",
      "t8 dedian oy\n",
      "cedoo od\n",
      "Epoch 84/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4657 - val_loss: 1.4718\n",
      "labrosa oy\n",
      "yhinap oy\n",
      "tecacter oy\n",
      "Epoch 85/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4648 - val_loss: 1.4709\n",
      "ib bund ab\n",
      "confartes oy\n",
      "buttema iy\n",
      "Epoch 86/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4638 - val_loss: 1.4700\n",
      "innos laa oy\n",
      "anyhit oy\n",
      "ypsintalmi oy\n",
      "Epoch 87/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4627 - val_loss: 1.4687\n",
      "tiatore oy\n",
      "9 myyodsä fa\n",
      "fbeetb oy\n",
      "Epoch 88/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4615 - val_loss: 1.4676\n",
      "epotare oy\n",
      "venix oy\n",
      "trecon oy\n",
      "Epoch 89/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4604 - val_loss: 1.4666\n",
      "con oy\n",
      "hefix oy\n",
      "mm rotan oy\n",
      "Epoch 90/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4595 - val_loss: 1.4657\n",
      "asinara oy\n",
      "rsod sene oy\n",
      "kj khiräst oy\n",
      "Epoch 91/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4585 - val_loss: 1.4646\n",
      "ronisa oy\n",
      "nnotdut oy\n",
      "bsmori oy\n",
      "Epoch 92/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4575 - val_loss: 1.4637\n",
      "ccannen oy\n",
      "1 2uod oy\n",
      "lamttak oy\n",
      "Epoch 93/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4565 - val_loss: 1.4628\n",
      "la sa oy\n",
      "oldi ciol ab\n",
      "zalles oy\n",
      "Epoch 94/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4555 - val_loss: 1.4618\n",
      "ådeat oy\n",
      "lndmeno oy\n",
      "jute oy\n",
      "Epoch 95/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4546 - val_loss: 1.4609\n",
      "gga seres oy\n",
      "oty g om\n",
      "xcepastre oy\n",
      "Epoch 96/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4536 - val_loss: 1.4601\n",
      "kannor oy\n",
      "centt inas oy\n",
      "damitra oy\n",
      "Epoch 97/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4527 - val_loss: 1.4592\n",
      "v5 tradus oy\n",
      "äkkötrut oy\n",
      " t heenst ab\n",
      "Epoch 98/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4519 - val_loss: 1.4584\n",
      "nat riak oy\n",
      "leton oy\n",
      "bg sifin4 oy\n",
      "Epoch 99/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4510 - val_loss: 1.4580\n",
      "7 ranintsa oy\n",
      "agnem oy\n",
      "zab by oy\n",
      "Epoch 100/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4503 - val_loss: 1.4565\n",
      "icosu oy\n",
      "otrasst oy\n",
      "mxer oy\n",
      "Epoch 101/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4491 - val_loss: 1.4557\n",
      "rajareva oy\n",
      "nuuspare oy\n",
      "äsfix oy\n",
      "Epoch 102/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4482 - val_loss: 1.4547\n",
      "nompi oy\n",
      "lannc oy\n",
      "kökarahon oy\n",
      "Epoch 103/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4473 - val_loss: 1.4541\n",
      "\n",
      ".tre rone oy\n",
      "codes oy\n",
      "Epoch 104/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4465 - val_loss: 1.4530\n",
      "londa oy\n",
      "finsean oy\n",
      "cob öy oy\n",
      "Epoch 105/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4456 - val_loss: 1.4522\n",
      "rsirtin oy\n",
      "wyndaco oy\n",
      "meto oy\n",
      "Epoch 106/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4447 - val_loss: 1.4514\n",
      "3jal oy\n",
      "telaaste oy\n",
      "mjat finn oy\n",
      "Epoch 107/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4439 - val_loss: 1.4506\n",
      "  oy nasjamot \n",
      "laka bent oy\n",
      "r kkikuuto oy\n",
      "Epoch 108/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4430 - val_loss: 1.4497\n",
      "astoper oy\n",
      "hasti fo oy\n",
      "lemf yrti oy\n",
      "Epoch 109/1000\n",
      "92825/92825 [==============================] - 2s 22us/step - loss: 1.4423 - val_loss: 1.4491\n",
      "usevest oy\n",
      "deare oy\n",
      "q4 oy\n",
      "Epoch 110/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4415 - val_loss: 1.4482\n",
      "lldist oy\n",
      "glordes oy\n",
      "er pymicon oy\n",
      "Epoch 111/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4407 - val_loss: 1.4478\n",
      "hd canra oy\n",
      "0 deet oy\n",
      "upomä oy\n",
      "Epoch 112/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4399 - val_loss: 1.4467\n",
      "8 malukasmi oy\n",
      "l3tero oy\n",
      "lemsiads oy\n",
      "Epoch 113/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4391 - val_loss: 1.4459\n",
      "vaiu htusse oy\n",
      "kotmat oy\n",
      "7s117 oy\n",
      "Epoch 114/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4383 - val_loss: 1.4452\n",
      "frab group oy\n",
      "aantit oy\n",
      "loba oy\n",
      "Epoch 115/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4375 - val_loss: 1.4446\n",
      "laatin oy\n",
      "iins oy\n",
      "rnsin oy\n",
      "Epoch 116/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4368 - val_loss: 1.4440\n",
      "smella oy\n",
      "uu kisäki oy\n",
      "td oy\n",
      "Epoch 117/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4361 - val_loss: 1.4432\n",
      "zpores oy\n",
      "lakkarice oy\n",
      "umixk oy\n",
      "Epoch 118/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4355 - val_loss: 1.4425\n",
      "ginoro oy\n",
      "on oy\n",
      "japtam oy\n",
      "Epoch 119/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4346 - val_loss: 1.4417\n",
      "äsiver oy\n",
      "zanz oy\n",
      "asdinda oy\n",
      "Epoch 120/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4339 - val_loss: 1.4410\n",
      "nscal groupa o\n",
      "100 y mriver i\n",
      "umi trose lad\n",
      "Epoch 121/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4332 - val_loss: 1.4404\n",
      "xoc sata oy\n",
      "kaukotyivä oy\n",
      "rads crads oy\n",
      "Epoch 122/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4324 - val_loss: 1.4397\n",
      "coms stres oy\n",
      "trakes oy\n",
      "gedax oy\n",
      "Epoch 123/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4317 - val_loss: 1.4392\n",
      "bearf oy\n",
      "zenea od\n",
      "eg trof oy\n",
      "Epoch 124/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4312 - val_loss: 1.4384\n",
      "arnec oy\n",
      "got4runt oy\n",
      "jv bodgege oy\n",
      "Epoch 125/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4304 - val_loss: 1.4377\n",
      "mårt oy\n",
      "genigs oy\n",
      "wc aszora oy\n",
      "Epoch 126/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4297 - val_loss: 1.4372\n",
      "59 mavama oy\n",
      "ljetu oy\n",
      "mm prodeg oy\n",
      "Epoch 127/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4291 - val_loss: 1.4365\n",
      "ukinemä oy\n",
      "macinum oy\n",
      "jajaka oy\n",
      "Epoch 128/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4284 - val_loss: 1.4362\n",
      "wuto oy latd\n",
      "jahkicalo oy\n",
      "rk semi oy\n",
      "Epoch 129/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4278 - val_loss: 1.4352\n",
      "bs teals oy\n",
      "dowemer oy\n",
      "kerus oy\n",
      "Epoch 130/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4271 - val_loss: 1.4347\n",
      "invoner oy\n",
      "closk oy\n",
      "vet prone oy\n",
      "Epoch 131/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4264 - val_loss: 1.4341\n",
      "\n",
      "ygkod oy\n",
      "\n",
      "Epoch 132/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4258 - val_loss: 1.4334\n",
      "73 ymjp oy\n",
      "abini st oy\n",
      "mor an oy\n",
      "Epoch 133/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4252 - val_loss: 1.4330\n",
      "k meenta oy\n",
      "co mark oy\n",
      "rato oy\n",
      "Epoch 134/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4245 - val_loss: 1.4323\n",
      "rs deni oy\n",
      "s medebaco oy\n",
      "mat oyj\n",
      "Epoch 135/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4239 - val_loss: 1.4317\n",
      "redesal oy\n",
      "meniira oy\n",
      "uklina oy\n",
      "Epoch 136/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4234 - val_loss: 1.4313\n",
      "baneko oy\n",
      "hytimini oy\n",
      "int nilu oy\n",
      "Epoch 137/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4229 - val_loss: 1.4308\n",
      "5 oy\n",
      "one ress oy\n",
      "gnecol oy\n",
      "Epoch 138/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4222 - val_loss: 1.4300\n",
      "nenorid oy\n",
      "ckab able ab\n",
      "lusua oy\n",
      "Epoch 139/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4215 - val_loss: 1.4296\n",
      "titupala oy\n",
      "cred oy\n",
      "wel oy\n",
      "Epoch 140/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4210 - val_loss: 1.4290\n",
      "åkno yy\n",
      "rk halti oy\n",
      "tmekec oy\n",
      "Epoch 141/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4204 - val_loss: 1.4286\n",
      "7cs oy\n",
      "gsobaa oy\n",
      "juruk oy\n",
      "Epoch 142/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4198 - val_loss: 1.4280\n",
      "ppli lage oy\n",
      "set sat oy\n",
      "ront oy\n",
      "Epoch 143/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4193 - val_loss: 1.4279\n",
      "cubbops oy\n",
      "withala oy\n",
      "6p ercomot oy\n",
      "Epoch 144/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4188 - val_loss: 1.4269\n",
      "ph auto oy\n",
      "showerd oy\n",
      "tomi oy\n",
      "Epoch 145/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4182 - val_loss: 1.4265\n",
      "buti oy\n",
      "0aw k oy\n",
      "3c my mideatka\n",
      "Epoch 146/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4176 - val_loss: 1.4259\n",
      "incom oy\n",
      "mynikumi oy\n",
      "74 finland oy\n",
      "Epoch 147/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4170 - val_loss: 1.4254\n",
      "pentari oy\n",
      "amaring oy\n",
      "eriix oy\n",
      "Epoch 148/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4164 - val_loss: 1.4249\n",
      "thati oy\n",
      "y\n",
      "ycova oy\n",
      "Epoch 149/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4159 - val_loss: 1.4244\n",
      "åil gronff ab\n",
      "in oy\n",
      "erpp media oy\n",
      "Epoch 150/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4154 - val_loss: 1.4239\n",
      "teks omsi oy\n",
      "gnowo oy\n",
      "h23 mynes oy\n",
      "Epoch 151/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4150 - val_loss: 1.4235\n",
      "3dl midia oy\n",
      "buntice oy\n",
      "\n",
      "Epoch 152/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4145 - val_loss: 1.4231\n",
      "milama oy\n",
      "lugande oy\n",
      "flector oy\n",
      "Epoch 153/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4139 - val_loss: 1.4225\n",
      "konsan oy\n",
      "iphetti oy\n",
      "l\n",
      "Epoch 154/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4133 - val_loss: 1.4221\n",
      "hti a oy\n",
      "atsi oy\n",
      "varu oy\n",
      "Epoch 155/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4129 - val_loss: 1.4215\n",
      "iniste oy\n",
      "rk pintan oy\n",
      "quimi oy\n",
      "Epoch 156/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4123 - val_loss: 1.4210\n",
      "äm yhtinän oy\n",
      "woro oy\n",
      "fisan oy\n",
      "Epoch 157/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4118 - val_loss: 1.4206\n",
      "200 oyj\n",
      "udvirek oy\n",
      "yqmed ab\n",
      "Epoch 158/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4114 - val_loss: 1.4203\n",
      "yblecort oy\n",
      "ekt inveat oy\n",
      "uke autoo oy\n",
      "Epoch 159/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4108 - val_loss: 1.4197\n",
      "qzade ab\n",
      "2gkor oy\n",
      "rh service oy\n",
      "Epoch 160/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4103 - val_loss: 1.4192\n",
      "texib oy\n",
      "8 stad ab\n",
      "fiova oy\n",
      "Epoch 161/1000\n",
      "92825/92825 [==============================] - 2s 22us/step - loss: 1.4098 - val_loss: 1.4186\n",
      "luka oy\n",
      "jyndabet oy\n",
      "3dige oy\n",
      "Epoch 162/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4093 - val_loss: 1.4183\n",
      "redi oy\n",
      "rk laalit oy\n",
      "gröridit oy\n",
      "Epoch 163/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4088 - val_loss: 1.4180\n",
      "y\n",
      "yshkis mar oy\n",
      "uoto oy\n",
      "Epoch 164/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4084 - val_loss: 1.4175\n",
      "rulak oy\n",
      "ntorma oy\n",
      "fatasi oy\n",
      "Epoch 165/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4079 - val_loss: 1.4170\n",
      "doi oy\n",
      "bl bux oy\n",
      "tsäjäklä oy\n",
      "Epoch 166/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4074 - val_loss: 1.4165\n",
      "loy ab\n",
      "rhelloy ab\n",
      "170 oy\n",
      "Epoch 167/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4070 - val_loss: 1.4163\n",
      "xy oy\n",
      "ms saino oy\n",
      "jövima oy\n",
      "Epoch 168/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4066 - val_loss: 1.4157\n",
      "8qu oy\n",
      "letaresä oy\n",
      "zera oy\n",
      "Epoch 169/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4060 - val_loss: 1.4153\n",
      "kramex oy\n",
      "lestor oy\n",
      "caderso oy\n",
      "Epoch 170/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4056 - val_loss: 1.4149\n",
      "ervs oy\n",
      "r4g broenc ab\n",
      "imlen oy\n",
      "Epoch 171/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4051 - val_loss: 1.4151\n",
      "mabwodan ab\n",
      "tykkivu oy\n",
      "i ami oy\n",
      "Epoch 172/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4048 - val_loss: 1.4145\n",
      "pork cuns oy\n",
      "jajaa oy\n",
      "ulvatu oy\n",
      "Epoch 173/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4044 - val_loss: 1.4141\n",
      "tjote oy\n",
      "ebcosa oy\n",
      "kame oy\n",
      "Epoch 174/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4038 - val_loss: 1.4132\n",
      "uspou oy\n",
      "2 5 79 oy\n",
      "2 oy\n",
      "Epoch 175/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4034 - val_loss: 1.4129\n",
      "bålsa ltd\n",
      "steni oy\n",
      "l3d oy\n",
      "Epoch 176/1000\n",
      "92825/92825 [==============================] - 2s 20us/step - loss: 1.4029 - val_loss: 1.4125\n",
      "vansuu oy\n",
      "jastar oy\n",
      "uline oy\n",
      "Epoch 177/1000\n",
      "92825/92825 [==============================] - 2s 21us/step - loss: 1.4025 - val_loss: 1.4125\n",
      "pyrus oy\n",
      "depis oy\n",
      "eht stof oy\n",
      "Epoch 178/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4021 - val_loss: 1.4116\n",
      "x ffeks oy\n",
      "wobrot oy\n",
      "kholad ab\n",
      "Epoch 179/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4016 - val_loss: 1.4114\n",
      "xia oy\n",
      "visel oy\n",
      "onnery oy\n",
      "Epoch 180/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4012 - val_loss: 1.4109\n",
      "zaset oy\n",
      "ax medit oy\n",
      "supas oy\n",
      "Epoch 181/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4008 - val_loss: 1.4106\n",
      "sbolk rint oy\n",
      "kä sähjö oy\n",
      "ohfinvent oy\n",
      "Epoch 182/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.4004 - val_loss: 1.4101\n",
      "nq asennus oy\n",
      "noisas oy\n",
      "hydwas ab\n",
      "Epoch 183/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3999 - val_loss: 1.4097\n",
      "nasta oy\n",
      "gransum oy\n",
      "lmetuco oy\n",
      "Epoch 184/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3995 - val_loss: 1.4094\n",
      "stemiteam oy\n",
      "dist oy\n",
      "8 3 1 oy\n",
      "Epoch 185/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3991 - val_loss: 1.4090\n",
      "lastam oy\n",
      "supirsämpö oy\n",
      "0 kexter oy\n",
      "Epoch 186/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3987 - val_loss: 1.4086\n",
      "tomas oy\n",
      "eqoaj oy\n",
      "vilmar oy\n",
      "Epoch 187/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3983 - val_loss: 1.4083\n",
      "eski time oy\n",
      "toabsox oy\n",
      "l oy maiubab\n",
      "Epoch 188/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3980 - val_loss: 1.4079\n",
      "acmor oy\n",
      "bbolimy oy\n",
      "tovax oy\n",
      "Epoch 189/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3977 - val_loss: 1.4076\n",
      "rwio oy\n",
      "s syht mediam\n",
      "ux oy\n",
      "Epoch 190/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3971 - val_loss: 1.4074\n",
      "ableene oy\n",
      "qs as\n",
      "böb lahte oy\n",
      "Epoch 191/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3967 - val_loss: 1.4067\n",
      "agat oy\n",
      "ista oy\n",
      "innofu oy\n",
      "Epoch 192/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3963 - val_loss: 1.4065\n",
      "mjt propaat oy\n",
      "lidoo oy\n",
      "junarin oy\n",
      "Epoch 193/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3959 - val_loss: 1.4061\n",
      "centawerd oy\n",
      "jss maiki oy\n",
      "defe oy\n",
      "Epoch 194/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3955 - val_loss: 1.4057\n",
      "ylmatui oy\n",
      "lemed oy\n",
      "lpopek oy\n",
      "Epoch 195/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3951 - val_loss: 1.4054\n",
      "xun oy\n",
      "isserto od\n",
      "startem oy\n",
      "Epoch 196/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3947 - val_loss: 1.4050\n",
      "1150 oy\n",
      "9t oy\n",
      "ämessäho oy\n",
      "Epoch 197/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3943 - val_loss: 1.4048\n",
      "0sto oy\n",
      "duset oy\n",
      "inlaija oy\n",
      "Epoch 198/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3941 - val_loss: 1.4043\n",
      "gnord oy\n",
      "jboplea oy\n",
      "körma oy\n",
      "Epoch 199/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3937 - val_loss: 1.4040\n",
      "4paty oy\n",
      "ivere oy\n",
      "alum ab\n",
      "Epoch 200/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3933 - val_loss: 1.4037\n",
      "4tyo oy\n",
      "lameti oy\n",
      "oy belmery ab\n",
      "Epoch 201/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3929 - val_loss: 1.4032\n",
      "jampo oy\n",
      "7sbo oy\n",
      "gnyl spota oy\n",
      "Epoch 202/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3925 - val_loss: 1.4031\n",
      "yokokinjä oy\n",
      "dufit oy\n",
      "ancora oy\n",
      "Epoch 203/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3921 - val_loss: 1.4026\n",
      "bohi immo oy\n",
      "lago oy\n",
      "lodas oy\n",
      "Epoch 204/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3916 - val_loss: 1.4023\n",
      "heloo oy\n",
      "vestan oy\n",
      "ksandon oy\n",
      "Epoch 205/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3914 - val_loss: 1.4022\n",
      "3 länt oy\n",
      "0 oy\n",
      "ystaspu oy\n",
      "Epoch 206/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3911 - val_loss: 1.4017\n",
      "tcardava oy\n",
      "3spei oy\n",
      "cbdeso ompli o\n",
      "Epoch 207/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3907 - val_loss: 1.4013\n",
      "kurtemaa oy\n",
      "hearica oy\n",
      "coft oy\n",
      "Epoch 208/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3903 - val_loss: 1.4012\n",
      "igasern oy\n",
      "ylähtilä oy\n",
      "ize oy\n",
      "Epoch 209/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3899 - val_loss: 1.4006\n",
      "vijok oy\n",
      "sivilo oy\n",
      "gold semenco o\n",
      "Epoch 210/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3895 - val_loss: 1.4003\n",
      "näväl oy\n",
      "lexex oy\n",
      "lmetsa oy\n",
      "Epoch 211/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3892 - val_loss: 1.3999\n",
      "2 stage oy\n",
      "ygboint oy\n",
      "tecoss oy\n",
      "Epoch 212/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3888 - val_loss: 1.3997\n",
      "afet oy\n",
      "grbepec oy\n",
      "enmat oy\n",
      "Epoch 213/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3885 - val_loss: 1.3994\n",
      "5184 oy\n",
      "q invest oy\n",
      "läiko oy\n",
      "Epoch 214/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3881 - val_loss: 1.3991\n",
      "xvitain oy\n",
      "pinter oy\n",
      "octer oy\n",
      "Epoch 215/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3878 - val_loss: 1.3989\n",
      "cahomex oy\n",
      "x oy ab\n",
      "karafi oy\n",
      "Epoch 216/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3874 - val_loss: 1.3984\n",
      "ngo oy\n",
      "upudic oy\n",
      "ripaart oy\n",
      "Epoch 217/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3871 - val_loss: 1.3981\n",
      "rhishyme oy\n",
      "kasaer oy\n",
      "årdes oy\n",
      "Epoch 218/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3868 - val_loss: 1.3978\n",
      "bhrouski ab\n",
      "la lin oy\n",
      "2 kreakst oy\n",
      "Epoch 219/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3866 - val_loss: 1.3975\n",
      "kerpik oy\n",
      "zoofp ab\n",
      "rs rash oy\n",
      "Epoch 220/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3863 - val_loss: 1.3973\n",
      "10 oy\n",
      "witrasa oy\n",
      "rmindo oy\n",
      "Epoch 221/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3858 - val_loss: 1.3970\n",
      "174 oy\n",
      "rail oy\n",
      "swasorc oy\n",
      "Epoch 222/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3855 - val_loss: 1.3967\n",
      "demab oy\n",
      "jatec oy\n",
      "ekis oy\n",
      "Epoch 223/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3851 - val_loss: 1.3964\n",
      "carak oy\n",
      "ofu oy\n",
      "ivo pojtt oy\n",
      "Epoch 224/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3848 - val_loss: 1.3961\n",
      "jespujeca oy\n",
      "\n",
      "ytockis oy\n",
      "Epoch 225/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3844 - val_loss: 1.3959\n",
      "854 stab oy\n",
      "tywäät oy\n",
      "atuola oy\n",
      "Epoch 226/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3842 - val_loss: 1.3955\n",
      "r3 fland oy\n",
      "ymön raine oy\n",
      "logont oy\n",
      "Epoch 227/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3838 - val_loss: 1.3951\n",
      "jistis oy\n",
      "kukce oy\n",
      "3ts oy\n",
      "Epoch 228/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3835 - val_loss: 1.3950\n",
      "eqool oy\n",
      "7b rystox oy\n",
      "op oy\n",
      "Epoch 229/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3832 - val_loss: 1.3947\n",
      "nimot oy\n",
      "zio oy\n",
      "xim oy\n",
      "Epoch 230/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3829 - val_loss: 1.3946\n",
      "84 ilvest oy\n",
      "mute arlo oy\n",
      " dord oy\n",
      "Epoch 231/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3826 - val_loss: 1.3942\n",
      "pusta kkyy\n",
      "voi comp oy\n",
      "979 oy\n",
      "Epoch 232/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3823 - val_loss: 1.3938\n",
      "ojara oy\n",
      "onvysa oy\n",
      "zeek oy\n",
      "Epoch 233/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3819 - val_loss: 1.3936\n",
      "2b stan oy\n",
      "chedalis oy\n",
      "qs s oy\n",
      "Epoch 234/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3816 - val_loss: 1.3932\n",
      "oy idvaalona\n",
      "nabood oy\n",
      "öfranss oy\n",
      "Epoch 235/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3813 - val_loss: 1.3931\n",
      "cobnsy oy\n",
      "ello oy\n",
      "k247 oy\n",
      "Epoch 236/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3810 - val_loss: 1.3927\n",
      "ideandie oy\n",
      "yvimer oy\n",
      "werplas oy\n",
      "Epoch 237/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3806 - val_loss: 1.3927\n",
      "vla hoonid oy\n",
      "511 bylsty\n",
      "ivpix oy\n",
      "Epoch 238/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3804 - val_loss: 1.3922\n",
      "linse oy\n",
      "tapa oy\n",
      "ba bapan as\n",
      "Epoch 239/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3800 - val_loss: 1.3919\n",
      "zön vt oy\n",
      "mettiö oy\n",
      "n4tias oy\n",
      "Epoch 240/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3798 - val_loss: 1.3916\n",
      "ret oy\n",
      "adsan oy\n",
      "b hyde gy ab\n",
      "Epoch 241/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3795 - val_loss: 1.3913\n",
      "ristal oy\n",
      "gajo oy\n",
      "pone oy\n",
      "Epoch 242/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3791 - val_loss: 1.3912\n",
      "onza oy\n",
      "quilla oy\n",
      "unt sive oy\n",
      "Epoch 243/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3789 - val_loss: 1.3910\n",
      "brassin oy\n",
      "xiir oy\n",
      "elu oy\n",
      "Epoch 244/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3786 - val_loss: 1.3906\n",
      "itek oy\n",
      "ahset oy\n",
      "nia oy asni\n",
      "Epoch 245/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3783 - val_loss: 1.3903\n",
      "ajatam oy\n",
      "ukitat oy\n",
      "yson oy\n",
      "Epoch 246/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3779 - val_loss: 1.3901\n",
      "98 arto oy\n",
      "eloro oy\n",
      "heflum oy\n",
      "Epoch 247/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3776 - val_loss: 1.3898\n",
      "ined sofi oy\n",
      "est atjay oy\n",
      "wellix oy\n",
      "Epoch 248/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3774 - val_loss: 1.3895\n",
      "åld oy\n",
      "mikal oy\n",
      "qu oy\n",
      "Epoch 249/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3770 - val_loss: 1.3894\n",
      "åger oy\n",
      "lihkenar oy\n",
      "\n",
      "Epoch 250/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3768 - val_loss: 1.3891\n",
      " jt secas oy\n",
      "t met oy\n",
      "lidaamine oy\n",
      "Epoch 251/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3765 - val_loss: 1.3889\n",
      "sirhull oy\n",
      "hyrit oy\n",
      "vip oy\n",
      "Epoch 252/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3762 - val_loss: 1.3886\n",
      "s oy\n",
      "yinon oy\n",
      "india ab\n",
      "Epoch 253/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3759 - val_loss: 1.3883\n",
      "wasfl oy\n",
      "umproke oy\n",
      "8igs oy\n",
      "Epoch 254/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3756 - val_loss: 1.3882\n",
      "7hakeit oy\n",
      "chtrge lux oy\n",
      "vpinan oy\n",
      "Epoch 255/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3754 - val_loss: 1.3878\n",
      "purty oy\n",
      "lfat oy\n",
      "mex ab\n",
      "Epoch 256/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3751 - val_loss: 1.3876\n",
      "ådy bc aqu\n",
      "ws dalan oy\n",
      "viso oy\n",
      "Epoch 257/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3748 - val_loss: 1.3873\n",
      "hmalffon oy\n",
      "t ab avof\n",
      "oso oy\n",
      "Epoch 258/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3746 - val_loss: 1.3872\n",
      "comon rakse oy\n",
      "lo jb yymb\n",
      "kos on oy\n",
      "Epoch 259/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3743 - val_loss: 1.3868\n",
      "nkeso oy\n",
      "pottile oy\n",
      " oy\n",
      "Epoch 260/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3740 - val_loss: 1.3868\n",
      "gleet oy\n",
      "emico oy\n",
      "rtiel oy\n",
      "Epoch 261/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3738 - val_loss: 1.3863\n",
      " ke cessan ab\n",
      "valsar oy\n",
      "opmi oy\n",
      "Epoch 262/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3734 - val_loss: 1.3862\n",
      "amtea oy\n",
      "i kaste oy\n",
      "ydaddem oy\n",
      "Epoch 263/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3732 - val_loss: 1.3860\n",
      "byodus oy\n",
      "rvi pest oy\n",
      "jaju myjt ab\n",
      "Epoch 264/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3729 - val_loss: 1.3857\n",
      "q ab ab\n",
      "y89 3 oy\n",
      "qvede oy\n",
      "Epoch 265/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3728 - val_loss: 1.3857\n",
      "va invest oy\n",
      "pälva oy\n",
      "skatuka oy\n",
      "Epoch 266/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3724 - val_loss: 1.3855\n",
      "fenrast oy\n",
      "xmecert oy\n",
      "jk groub oy\n",
      "Epoch 267/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3722 - val_loss: 1.3851\n",
      "jolla tech oy\n",
      "a ida oy\n",
      "dini oy\n",
      "Epoch 268/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3719 - val_loss: 1.3848\n",
      "onino oy\n",
      " oy\n",
      "y foxt oy\n",
      "Epoch 269/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3716 - val_loss: 1.3846\n",
      "eferti oy\n",
      "517 oy\n",
      "betrovi oy\n",
      "Epoch 270/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3714 - val_loss: 1.3844\n",
      "ehons oy\n",
      "margea oy\n",
      "jete oy\n",
      "Epoch 271/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3711 - val_loss: 1.3843\n",
      "vlased oy\n",
      "desito oy\n",
      "iho oy\n",
      "Epoch 272/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3709 - val_loss: 1.3839\n",
      "kmeriket oy\n",
      "äske oy\n",
      "meritex oy\n",
      "Epoch 273/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3705 - val_loss: 1.3836\n",
      "h roy oy\n",
      "ogespro oy\n",
      "ne profi oy\n",
      "Epoch 274/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3703 - val_loss: 1.3835\n",
      "tila oy\n",
      "b kon stol\n",
      "pinkor oy\n",
      "Epoch 275/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3700 - val_loss: 1.3833\n",
      "fj piltala oy\n",
      "y takuons\n",
      "vatartus oy\n",
      "Epoch 276/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3698 - val_loss: 1.3830\n",
      "hd group oy\n",
      "finone oy\n",
      "4sa villa oy\n",
      "Epoch 277/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3696 - val_loss: 1.3831\n",
      "ehmityura oy\n",
      "next oy\n",
      "4recartoru oy\n",
      "Epoch 278/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3693 - val_loss: 1.3825\n",
      "inghit oy\n",
      "himolio oy\n",
      "bannov oy\n",
      "Epoch 279/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3690 - val_loss: 1.3828\n",
      "ötieche oy\n",
      "coderbaje oy\n",
      "d essus oy\n",
      "Epoch 280/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3689 - val_loss: 1.3823\n",
      "lovia oy\n",
      "oo\n",
      "gituk oy\n",
      "Epoch 281/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3686 - val_loss: 1.3819\n",
      "y oy\n",
      "yqsi oy\n",
      "test oy\n",
      "Epoch 282/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3683 - val_loss: 1.3819\n",
      "edi hurit oy\n",
      "8 lind oy\n",
      "re trumi oy\n",
      "Epoch 283/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3680 - val_loss: 1.3817\n",
      "qial oy\n",
      "ajauno groy\n",
      "econde oy\n",
      "Epoch 284/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3678 - val_loss: 1.3816\n",
      "intar oy\n",
      "oy lvap zyöt a\n",
      "rada oy\n",
      "Epoch 285/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3676 - val_loss: 1.3812\n",
      "agnode oy\n",
      "dectoc oy\n",
      "tmaruka oy\n",
      "Epoch 286/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3674 - val_loss: 1.3811\n",
      "nöfre oy\n",
      "flexba oy\n",
      "kida oy\n",
      "Epoch 287/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3671 - val_loss: 1.3807\n",
      "vevellam oy\n",
      "xato oy\n",
      "htylym oy\n",
      "Epoch 288/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3669 - val_loss: 1.3808\n",
      "poljest oy\n",
      "raki oy\n",
      "gwoy oy\n",
      "Epoch 289/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3667 - val_loss: 1.3804\n",
      "pne oy\n",
      "ta grans oy\n",
      "lahti oyj\n",
      "Epoch 290/1000\n",
      "92825/92825 [==============================] - 2s 17us/step - loss: 1.3664 - val_loss: 1.3801\n",
      "100 oy\n",
      "ar56 oy\n",
      "brimit oy\n",
      "Epoch 291/1000\n",
      "90112/92825 [============================>.] - ETA: 0s - loss: 1.3661"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-408-8b414b63ca40>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"adam\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mhistory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8192\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprint_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    184\u001b[0m                             fit_inputs[:-1], batch_ids) + [fit_inputs[-1]]\n\u001b[1;32m    185\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m                         \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfit_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m                     raise TypeError('TypeError while preparing batch. '\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mslice_arrays\u001b[0;34m(arrays, start, stop)\u001b[0m\n\u001b[1;32m    553\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    553\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "opt=keras.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"adam\")\n",
    "\n",
    "history=model.fit(Xf, Yf, batch_size=8192, validation_split=0.1,  epochs=1000, shuffle=True, callbacks=[print_callback],verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x1152 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "results=history\n",
    "\n",
    "plt.figure(figsize=(8, 16))\n",
    "plt.title(\"Learning curve\")\n",
    "plt.plot(results.history[\"loss\"], label=\"loss\")\n",
    "plt.plot(results.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot( np.argmin(results.history[\"val_loss\"]), np.min(results.history[\"val_loss\"]), marker=\"x\", color=\"r\", label=\"best model\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"log_loss\")\n",
    "plt.legend();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# beam search\n",
    "# end of line character should be zeros\n",
    "# dropout\n",
    "# try GRU\n",
    "# save best model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_31 (LSTM)               (None, 15, 64)            27392     \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 15, 42)            2730      \n",
      "=================================================================\n",
      "Total params: 30,122\n",
      "Trainable params: 30,122\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers, models\n",
    "from keras.layers import Dense, Input, LSTM,GRU\n",
    "\n",
    "drp=0\n",
    "model=models.Sequential()\n",
    "model.add(LSTM(64, input_shape=(Tx, len(characters)),return_sequences=True,activation=\"softmax\"))\n",
    "model.add(Dense(len(characters),activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0000001 , 0.99999994, 1.0000001 , 1.        , 0.99999994,\n",
       "        1.        , 0.9999999 , 1.        , 0.99999994, 1.        ,\n",
       "        1.        , 0.9999999 , 0.99999994, 0.99999994, 1.        ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(model.predict(Xf[2:3,:,:]), axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.00751082, 0.00771122, 0.00736352, 0.00742367, 0.00828375,\n",
       "         0.00764484, 0.00781036, 0.00792186, 0.00830439, 0.00748659,\n",
       "         0.00785631, 0.00797882, 0.00748226, 0.00832559, 0.00816992,\n",
       "         0.00774464, 0.00837419, 0.00826431, 0.00754519, 0.00766723,\n",
       "         0.00760604, 0.00810976, 0.0081093 , 0.00816004, 0.00828095,\n",
       "         0.00825982, 0.00789951, 0.00796695, 0.0082077 , 0.00804529,\n",
       "         0.00817657, 0.00752608, 0.0077254 , 0.00817136, 0.00825257,\n",
       "         0.00773064, 0.00800089, 0.00743151, 0.00725482, 0.00816547,\n",
       "         0.00792588, 0.00814968, 0.00771759, 0.00809409, 0.00802816,\n",
       "         0.00765526, 0.00779734, 0.0077412 , 0.00772986, 0.0075444 ,\n",
       "         0.00780758, 0.00788464, 0.00762915, 0.00737183, 0.00761693,\n",
       "         0.00745591, 0.00751873, 0.00830413, 0.00732688, 0.00764269,\n",
       "         0.0083167 , 0.00755099, 0.00822983, 0.00765413],\n",
       "        [0.00826527, 0.00766256, 0.00776304, 0.00762692, 0.00736928,\n",
       "         0.00770531, 0.00731369, 0.0075045 , 0.00821238, 0.00756802,\n",
       "         0.00787387, 0.00792144, 0.00831404, 0.00779639, 0.00769126,\n",
       "         0.0078449 , 0.00736737, 0.00775291, 0.00760009, 0.00750063,\n",
       "         0.00799315, 0.00764332, 0.00831449, 0.00729678, 0.00796865,\n",
       "         0.00749808, 0.00805516, 0.00784612, 0.00780682, 0.00823988,\n",
       "         0.00749877, 0.00833057, 0.00820326, 0.00761411, 0.00753614,\n",
       "         0.00790919, 0.00831422, 0.00778705, 0.00767561, 0.00730049,\n",
       "         0.00737442, 0.00766449, 0.00801422, 0.00825962, 0.00824213,\n",
       "         0.00797972, 0.00779547, 0.00813357, 0.00797576, 0.00750979,\n",
       "         0.00801003, 0.00746579, 0.00732329, 0.00766472, 0.00736355,\n",
       "         0.00727188, 0.00742412, 0.00817286, 0.00750228, 0.00743521,\n",
       "         0.00730672, 0.00775168, 0.00814858, 0.00819413],\n",
       "        [0.00743799, 0.00760241, 0.00737839, 0.008326  , 0.00731772,\n",
       "         0.00786148, 0.00743721, 0.00749073, 0.00795403, 0.00817319,\n",
       "         0.00805483, 0.00819475, 0.00793917, 0.0077477 , 0.0081174 ,\n",
       "         0.00764925, 0.008085  , 0.00769011, 0.00730749, 0.00728836,\n",
       "         0.00788632, 0.00744275, 0.00813629, 0.00798192, 0.00748374,\n",
       "         0.00782252, 0.00818425, 0.00788259, 0.00727391, 0.00761238,\n",
       "         0.00774116, 0.00762853, 0.00734317, 0.00812893, 0.0072901 ,\n",
       "         0.00817079, 0.00771586, 0.00732058, 0.00769867, 0.00823587,\n",
       "         0.00833434, 0.00777107, 0.00760887, 0.0080744 , 0.00732611,\n",
       "         0.00739303, 0.00726273, 0.00796233, 0.00753575, 0.00759634,\n",
       "         0.00832499, 0.00797604, 0.00734019, 0.00731713, 0.00762544,\n",
       "         0.00800577, 0.00744617, 0.00835985, 0.00832233, 0.00775555,\n",
       "         0.00823774, 0.00833772, 0.00742275, 0.00757958],\n",
       "        [0.0077454 , 0.00822609, 0.00791149, 0.00829342, 0.00758428,\n",
       "         0.00735905, 0.00733233, 0.00790586, 0.00759252, 0.00778904,\n",
       "         0.00797546, 0.00811741, 0.00772046, 0.00748489, 0.00753946,\n",
       "         0.00760532, 0.0083061 , 0.00828977, 0.00776858, 0.00788167,\n",
       "         0.0080056 , 0.00812338, 0.00792399, 0.00753168, 0.00821621,\n",
       "         0.00834589, 0.00824505, 0.00771651, 0.00784379, 0.00772972,\n",
       "         0.0080072 , 0.0076558 , 0.0072889 , 0.00761928, 0.00751781,\n",
       "         0.00806201, 0.00773199, 0.00772962, 0.00745148, 0.00834782,\n",
       "         0.00810396, 0.00747656, 0.00734316, 0.00773581, 0.00740342,\n",
       "         0.00736738, 0.00783189, 0.00808059, 0.00831074, 0.00744036,\n",
       "         0.0083609 , 0.00735896, 0.00777635, 0.00759406, 0.00800033,\n",
       "         0.00833682, 0.00825499, 0.00735008, 0.00791148, 0.00760815,\n",
       "         0.00731047, 0.00733481, 0.00771988, 0.00732653],\n",
       "        [0.00773065, 0.00781867, 0.00765005, 0.00818289, 0.00734348,\n",
       "         0.00809945, 0.00809085, 0.00810848, 0.00775896, 0.00766836,\n",
       "         0.00837186, 0.00781008, 0.0079994 , 0.00820561, 0.00786172,\n",
       "         0.00756014, 0.00770788, 0.00737346, 0.0073772 , 0.00749933,\n",
       "         0.00761981, 0.00817008, 0.00776522, 0.00745459, 0.00769813,\n",
       "         0.00815983, 0.00831294, 0.0079958 , 0.00833547, 0.00823536,\n",
       "         0.00752085, 0.00745731, 0.00778356, 0.0081564 , 0.00819081,\n",
       "         0.00758854, 0.00823474, 0.00768951, 0.00827049, 0.00814169,\n",
       "         0.00777606, 0.00729533, 0.00800536, 0.00799374, 0.00751895,\n",
       "         0.00763657, 0.00809419, 0.00736453, 0.00736993, 0.00785885,\n",
       "         0.00731727, 0.00765869, 0.00726258, 0.00821819, 0.00794515,\n",
       "         0.00804188, 0.00830426, 0.00788436, 0.00741048, 0.00814152,\n",
       "         0.00828648, 0.00802898, 0.00786574, 0.00796248],\n",
       "        [0.00825665, 0.00764968, 0.00776058, 0.00762431, 0.00737287,\n",
       "         0.0076979 , 0.00731765, 0.00750497, 0.0082116 , 0.00756986,\n",
       "         0.00787915, 0.00791588, 0.00830496, 0.00780074, 0.00768544,\n",
       "         0.00784278, 0.0073652 , 0.00777667, 0.00759565, 0.00750361,\n",
       "         0.00798574, 0.0076417 , 0.00831249, 0.00729895, 0.00797953,\n",
       "         0.00748889, 0.00805109, 0.0078484 , 0.00780347, 0.00822963,\n",
       "         0.0074893 , 0.00833065, 0.00819655, 0.00761265, 0.00754446,\n",
       "         0.00791984, 0.00831434, 0.00778348, 0.00767916, 0.00729669,\n",
       "         0.0073828 , 0.00768204, 0.00801133, 0.00825966, 0.00824158,\n",
       "         0.00799158, 0.00779567, 0.00813734, 0.00799039, 0.00750677,\n",
       "         0.00800375, 0.00746816, 0.00731649, 0.00766479, 0.00735889,\n",
       "         0.00726931, 0.00743049, 0.00817311, 0.00749528, 0.00743687,\n",
       "         0.0073122 , 0.00775588, 0.00814653, 0.00819193],\n",
       "        [0.00771265, 0.00835237, 0.00819291, 0.0074709 , 0.00780582,\n",
       "         0.00729397, 0.00811501, 0.00740256, 0.00814648, 0.00824997,\n",
       "         0.00791322, 0.00809566, 0.00796627, 0.00786335, 0.00798291,\n",
       "         0.0078628 , 0.00783743, 0.00751222, 0.00740621, 0.00757292,\n",
       "         0.00806737, 0.00778682, 0.00783874, 0.00786852, 0.0074385 ,\n",
       "         0.00738657, 0.00756653, 0.00736166, 0.00811253, 0.00788022,\n",
       "         0.00813215, 0.00760277, 0.00732176, 0.00735736, 0.00824165,\n",
       "         0.00827849, 0.00834587, 0.00759351, 0.0079598 , 0.0076379 ,\n",
       "         0.00750156, 0.00821288, 0.00823024, 0.00758652, 0.00769309,\n",
       "         0.00734322, 0.00730058, 0.00780234, 0.00827829, 0.00795906,\n",
       "         0.0079121 , 0.00776829, 0.00794841, 0.00834441, 0.00771521,\n",
       "         0.00833829, 0.00742102, 0.00830594, 0.00728774, 0.0076153 ,\n",
       "         0.00814426, 0.00770957, 0.00789969, 0.00780394],\n",
       "        [0.00750048, 0.00797785, 0.00772231, 0.00838185, 0.00769319,\n",
       "         0.00778527, 0.00728317, 0.0079835 , 0.00758432, 0.00753619,\n",
       "         0.0080221 , 0.00751531, 0.00823745, 0.00803141, 0.00749707,\n",
       "         0.00802357, 0.00807777, 0.00734957, 0.00836409, 0.00805794,\n",
       "         0.00805477, 0.00758054, 0.0074598 , 0.00800361, 0.00799735,\n",
       "         0.00784657, 0.0078983 , 0.00778725, 0.00764796, 0.00827272,\n",
       "         0.00753602, 0.00737494, 0.00785853, 0.00767752, 0.00776947,\n",
       "         0.0079306 , 0.00758039, 0.00783396, 0.00792058, 0.00804723,\n",
       "         0.00816257, 0.00783981, 0.00771401, 0.00750177, 0.00781695,\n",
       "         0.00734837, 0.00754554, 0.0076168 , 0.00807699, 0.00821132,\n",
       "         0.00788824, 0.00746718, 0.00828501, 0.0072949 , 0.00771916,\n",
       "         0.00805078, 0.00771207, 0.0083374 , 0.00754962, 0.00802078,\n",
       "         0.0079286 , 0.00803642, 0.00835891, 0.00761023],\n",
       "        [0.00771538, 0.00835004, 0.00820121, 0.00747752, 0.00781576,\n",
       "         0.00729823, 0.00810962, 0.00740319, 0.00815733, 0.00825445,\n",
       "         0.00790913, 0.00810284, 0.00795878, 0.00785467, 0.0079766 ,\n",
       "         0.00785826, 0.00783068, 0.0075084 , 0.00740885, 0.00758389,\n",
       "         0.00806219, 0.00778869, 0.00783544, 0.00786361, 0.00743171,\n",
       "         0.0073944 , 0.00756389, 0.00735697, 0.00811535, 0.00789131,\n",
       "         0.00812875, 0.00759532, 0.00732958, 0.00735627, 0.0082438 ,\n",
       "         0.0082752 , 0.00834832, 0.00759159, 0.00795773, 0.00764373,\n",
       "         0.00749796, 0.00820954, 0.00823191, 0.00757918, 0.00768671,\n",
       "         0.00734949, 0.00729715, 0.00779775, 0.00826085, 0.00796143,\n",
       "         0.00791209, 0.00776133, 0.00795985, 0.00834015, 0.00772111,\n",
       "         0.00834426, 0.00743449, 0.00830545, 0.00728145, 0.00761845,\n",
       "         0.00813764, 0.00770218, 0.00790954, 0.00780386],\n",
       "        [0.00758968, 0.00827847, 0.00740763, 0.00817242, 0.00756464,\n",
       "         0.00745191, 0.00788462, 0.00751482, 0.00783729, 0.00753976,\n",
       "         0.00766296, 0.00815468, 0.00791552, 0.00814255, 0.00801929,\n",
       "         0.00806347, 0.00748086, 0.0081093 , 0.0073924 , 0.00764254,\n",
       "         0.00785802, 0.00794868, 0.00808077, 0.00829749, 0.00753206,\n",
       "         0.00834242, 0.00770561, 0.00765083, 0.00759041, 0.00817059,\n",
       "         0.00810431, 0.00737268, 0.00831766, 0.00775607, 0.0079755 ,\n",
       "         0.00838038, 0.00823291, 0.00767444, 0.00738996, 0.00796859,\n",
       "         0.00739261, 0.00738851, 0.00836142, 0.00755562, 0.00770423,\n",
       "         0.00742722, 0.0078632 , 0.00763377, 0.0077955 , 0.00726879,\n",
       "         0.00817773, 0.00787357, 0.00766138, 0.00726399, 0.00730321,\n",
       "         0.00832953, 0.00809593, 0.00766926, 0.00783937, 0.00790669,\n",
       "         0.00753126, 0.00774047, 0.00760147, 0.00831363],\n",
       "        [0.00738952, 0.00812216, 0.00790298, 0.00725995, 0.00767212,\n",
       "         0.00729666, 0.00798108, 0.00795186, 0.0080303 , 0.00778744,\n",
       "         0.00759118, 0.00791791, 0.00806951, 0.00755844, 0.00813481,\n",
       "         0.00774061, 0.00738752, 0.00786681, 0.00729533, 0.00770297,\n",
       "         0.00739241, 0.00766048, 0.00774048, 0.00778475, 0.00786389,\n",
       "         0.00780115, 0.00753964, 0.00749949, 0.00782143, 0.0076783 ,\n",
       "         0.00815986, 0.00783912, 0.00809817, 0.00785073, 0.00783059,\n",
       "         0.00741145, 0.00832789, 0.00834533, 0.00786369, 0.00773916,\n",
       "         0.00782615, 0.00806818, 0.00741136, 0.00751904, 0.00770433,\n",
       "         0.00762787, 0.00737614, 0.00758029, 0.00768536, 0.00729518,\n",
       "         0.00728985, 0.00758803, 0.00779877, 0.00752978, 0.00767177,\n",
       "         0.00746974, 0.00747769, 0.00752025, 0.00801592, 0.0076152 ,\n",
       "         0.00824861, 0.00779306, 0.00794471, 0.00815117],\n",
       "        [0.00810338, 0.00744458, 0.00758679, 0.00782059, 0.00743893,\n",
       "         0.00821071, 0.00752361, 0.00782726, 0.00826805, 0.00826938,\n",
       "         0.00744955, 0.00765986, 0.00754152, 0.00806372, 0.00821584,\n",
       "         0.0080175 , 0.00755894, 0.0076647 , 0.00757018, 0.00767901,\n",
       "         0.00836005, 0.00780091, 0.00824243, 0.00836152, 0.00776331,\n",
       "         0.00729797, 0.00746251, 0.00763147, 0.0077033 , 0.00783748,\n",
       "         0.00831408, 0.00830361, 0.00801814, 0.00810063, 0.00809243,\n",
       "         0.00759484, 0.00745061, 0.00803131, 0.0079657 , 0.00804152,\n",
       "         0.00784737, 0.00826029, 0.00774994, 0.00774665, 0.00750727,\n",
       "         0.00815594, 0.00787838, 0.0077365 , 0.00811089, 0.00788127,\n",
       "         0.0082732 , 0.00783655, 0.00768991, 0.00734234, 0.00752976,\n",
       "         0.00773727, 0.00787032, 0.00752792, 0.00773158, 0.00729768,\n",
       "         0.00757791, 0.00776171, 0.00774995, 0.0076283 ],\n",
       "        [0.0082238 , 0.00820849, 0.00729408, 0.00821432, 0.0079081 ,\n",
       "         0.00781594, 0.00823966, 0.00749455, 0.00820967, 0.00759691,\n",
       "         0.00755259, 0.00826676, 0.00821756, 0.00772822, 0.0080268 ,\n",
       "         0.00739332, 0.00814683, 0.00803799, 0.00814557, 0.00744145,\n",
       "         0.00751565, 0.00776624, 0.00777734, 0.00766791, 0.00814808,\n",
       "         0.00752695, 0.00756794, 0.00798763, 0.00780048, 0.00811685,\n",
       "         0.00727261, 0.00804807, 0.00813443, 0.00758845, 0.00816244,\n",
       "         0.00767431, 0.00751995, 0.00782696, 0.00736374, 0.00805233,\n",
       "         0.00754308, 0.00825748, 0.00832077, 0.00752554, 0.00774011,\n",
       "         0.00763719, 0.00790779, 0.00741162, 0.00752849, 0.00781712,\n",
       "         0.00784445, 0.00834762, 0.00741081, 0.00751229, 0.00800302,\n",
       "         0.00728108, 0.00744562, 0.00735338, 0.00784528, 0.00739953,\n",
       "         0.00739734, 0.00812611, 0.0075374 , 0.00730564],\n",
       "        [0.0080297 , 0.00775872, 0.00777121, 0.00753284, 0.00795043,\n",
       "         0.00731473, 0.00820973, 0.00728163, 0.00764205, 0.00802106,\n",
       "         0.00778581, 0.0081536 , 0.00827918, 0.00764988, 0.00727978,\n",
       "         0.00751072, 0.00830922, 0.0077916 , 0.00808656, 0.00742552,\n",
       "         0.00833821, 0.00761623, 0.00829595, 0.00743973, 0.00834294,\n",
       "         0.00810302, 0.00743401, 0.00759351, 0.00759107, 0.00782219,\n",
       "         0.00746907, 0.00736378, 0.00752876, 0.00830074, 0.00794817,\n",
       "         0.00799762, 0.00770991, 0.00828114, 0.00747435, 0.00765533,\n",
       "         0.00735438, 0.0075031 , 0.0076632 , 0.00747742, 0.00734236,\n",
       "         0.00759039, 0.00764605, 0.0082138 , 0.00813071, 0.00772169,\n",
       "         0.00828835, 0.00801988, 0.00802687, 0.00731282, 0.00763829,\n",
       "         0.00746682, 0.00730551, 0.00732774, 0.00751703, 0.00779755,\n",
       "         0.0073336 , 0.00816493, 0.00762946, 0.00742322],\n",
       "        [0.008035  , 0.00775207, 0.00778053, 0.00753435, 0.0079484 ,\n",
       "         0.00731414, 0.00820612, 0.00728881, 0.00764867, 0.00801501,\n",
       "         0.00779455, 0.00816168, 0.00826934, 0.00764444, 0.00729163,\n",
       "         0.00751377, 0.00830166, 0.00779182, 0.00808857, 0.00741903,\n",
       "         0.00833087, 0.00761107, 0.0083013 , 0.0074448 , 0.0083362 ,\n",
       "         0.00810492, 0.00743514, 0.00760041, 0.00759222, 0.00782259,\n",
       "         0.00747995, 0.0073665 , 0.00752163, 0.00830217, 0.0079523 ,\n",
       "         0.008004  , 0.0077061 , 0.00827354, 0.00747603, 0.00765398,\n",
       "         0.0073605 , 0.00750695, 0.00765704, 0.00747765, 0.00734696,\n",
       "         0.00758687, 0.00764593, 0.00821539, 0.00812243, 0.00772486,\n",
       "         0.00829397, 0.00801983, 0.00802831, 0.00731177, 0.00764308,\n",
       "         0.00746253, 0.00730076, 0.00732731, 0.00751733, 0.0077919 ,\n",
       "         0.00732479, 0.00816901, 0.00762618, 0.00741775]]], dtype=float32)"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(Xf[:1,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p36",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
